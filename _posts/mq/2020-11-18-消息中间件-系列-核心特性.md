---
layout: post
title: "MQ 系列 核心特性"
subtitle: '消息中间件基本特性'
author: "lichao"
header-img: "img/post-bg-rwd.jpg"
catalog: true
tags:
  - MQ
---

> 本文介绍消息 MQ 核心特性，并说明通用 MQ 中间件对这些核型特性的支持情况。

## 常用中间件
2011 年初， Linkin 开源了 Kafka 这个优秀的消息中间件，淘宝中间件团队在对 Kafka 做过充分 Review 之后，Kafka 无限消息堆积，高效的持久化速度吸引了我们，但是同时发现这个消息系统主要定位于日志传输，对于使用在淘宝交易、订单、充值等场景下还有诸多特性不满足，为此重新用 Java 语言编写了 RocketMQ，定位于非日志的可靠消息传输。

* RocketMQ：主要应用于高可用和低延迟线上业务
* Kakfa：主要应用于高吞吐的流式训练任务(近在线)和离线任务

## 订阅与发布
消息的发布是指某个生产者向某个 topic 发送消息；消息的订阅是指某个消费者关注了某个 topic 中带有某些tag的消息，进而从该topic消费数据。

## 消息优先级 Message Priority
消息优先级是指在一个消息队列中，每条消息都有不同的优先级，一般用整数来描述，优先级高的消息先投递，如果消息完全在一个内存队列中，那么在投递前可以按照优先级排序，令优先级高的先投递。对于优先级问题，可以归纳为 2 类：
1. 只要达到优先级目的即可，不是严格意义上的优先级，通常将优先级划分为高、中、低，或者再多几个级别。每个优先级用不同的 topic 表示，发消息时指定不同的 topic 来表示优先级，这种方式可以解决绝大部分的优先级问题，但是对业务中的优先级精确性做了妥协。
2. 严格优先级，优先级用整数表示，例如 0 ~ 65535 ，这种优先级问题一般使用不同 topic 解决就非常不合适。

> 如果要让 MQ 支持严格优先级，会对 MQ 的性能造成非常大的影响。

由于 RocketMQ/Kafka 所有消息都是持久化的，所以如果按照优先级来排序，开销会非常大，因此 RocketMQ/Kafka 没有特意支持消息优先级，但是可以通过变通的方式实现类似功能，即单独配置一个优先级高的队列，和一个普通优先级的队列， 将不同优先级发送到不同队列即可。

RabbitMQ 支持优先级概念, 通过数字说明优先级别, 最大支持 255, 在 RabbitMQ 内部, 每个 priority 都是一个 queue, 消息根据优先级路由到相应的queue 存储, 消费的时候, consumer 先处理完高优先级, 再处理低优先级别, 这样存在  「low priority hungry」 的问题. 

> 问题：如何实现 Consumer：[Kafka](https://qiankunli.github.io/2019/04/27/kafka_priority.html)
[Kafka优先级支持](https://www.menina.cn/article/103)

[Azure 优先级队列设计模式](https://docs.microsoft.com/zh-cn/azure/architecture/patterns/priority-queue)

## 消息顺序 Message Order

消息有序指的是一类消息消费时，能按照发送的顺序来消费。例如：一个订单产生了三条消息分别是订单创建、订单付款、订单完成。消费时要按照这个顺序消费才能有意义，但是同时订单之间是可以并行消费的。RocketMQ 可以严格的保证消息有序。

顺序消息分为全局顺序消息与分区顺序消息，全局顺序是指某个Topic下的所有消息都要保证顺序；部分顺序消息只要保证每一组消息被顺序消费即可。

* 全局顺序： 对于指定的一个 Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。 适用场景：性能要求不高，所有的消息严格按照 FIFO 原则进行消息发布和消费的场景
* 分区顺序： 对于指定的一个 Topic，所有消息根据 sharding key 进行区块分区。 同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。 Sharding key 是顺序消息中用来区分不同分区的关键字段，和普通消息的 Key 是完全不同的概念。 适用场景：性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。


## 消息重投

**结论：对于普通消息，消息发送默认采用round-robin机制来选择发送到哪一个队列，如果发送失败，默认重试2次。对于普通有序消息，RocketMQ是不会进行重试的。如果需要重试，那么业务RD同学需要自己编写重试代码，例如通过一个for循环，最多重试几次。对于严格有序消息，由于直接指定了一个MessageQueue。如果这个MessageQueue所在的Broker宕机了，那么之后的重试必然都失败。**

三种消息的类型介绍如下： 
* 普通消息：消息是无序的，任意发送到哪一个队列都可以。 
* 普通有序消息：同一类消息(例如某个用户的消息)总是发送到同一个队列，在异常情况下，也可以发送到其他队列。 
* 严格有序消息：消息必须被发送到同一个队列，即使在异常情况下，也不允许发送到其他队列。 
        
对于这三种类型的消息，RocketMQ 分别提供了对应的方法来发送消息，例如同步发送(异步/批量/oneway也是类似)： 
![消息消费](/img/rocketmq/123.png)

> 需要注意的是：
>> 这些方法重载形式，本意是为了支持以上三种不同的消息类型。但是不按套路出牌，例如：对于一个用户的多条消息，在调用第一种send方法形式时，依然在对于同一个用户每次发送消息时，选择了不同的队列(MessageQueue)，那么也没有人能阻止。这就忽略了 RocketMQ 团队设计这三个方法的意图。 
>> RocketMQ 客户端的生产者重试机制，只会普通消息有作用。对于普通有序消息、严格有序消息是没有作用。


**生产者在发送消息时，同步消息失败会重投，异步消息有重试，oneway没有任何保证。**消息重投保证消息尽可能发送成功、不丢失，但可能会造成消息重复，消息重复在RocketMQ中是无法避免的问题。消息重复在一般情况下不会发生，当出现消息量大、网络抖动，消息重复就会是大概率事件。另外，生产者主动重发、consumer负载变化也会导致重复消息。如下方法可以设置消息重试策略：

* retryTimesWhenSendFailed: 同步发送失败重投次数，默认为2，因此生产者会最多尝试发送retryTimesWhenSendFailed + 1次。不会选择上次失败的broker，尝试向其他broker发送，最大程度保证消息不丢。超过重投次数，抛出异常，由客户端保证消息不丢。当出现RemotingException、MQClientException和部分MQBrokerException时会重投。
* retryTimesWhenSendAsyncFailed: 异步发送失败重试次数，异步重试不会选择其他broker，仅在同一个broker上做重试，不保证消息不丢。
* retryAnotherBrokerWhenNotStoreOK: 消息刷盘（主或备）超时或slave不可用（返回状态非SEND_OK），是否尝试发送到其他broker，默认false。十分重要消息可以开启。

## 消费重试
Consumer消费消息失败后，要提供一种重试机制，令消息再消费一次。Consumer消费消息失败通常可以认为有以下几种情况：

* 由于消息本身的原因，例如反序列化失败，消息数据本身无法处理（例如话费充值，当前消息的手机号被注销，无法充值）等。这种错误通常需要跳过这条消息，再消费其它消息，而这条失败的消息即使立刻重试消费，99%也不成功，所以最好提供一种定时重试机制，即过10秒后再重试。
* 由于依赖的下游应用服务不可用，例如db连接不可用，外系统网络不可达等。遇到这种错误，即使跳过当前失败的消息，消费其他消息同样也会报错。这种情况建议应用sleep 30s，再消费下一条消息，这样可以减轻Broker重试消息的压力。

RocketMQ会为每个消费组都设置一个Topic名称为“%RETRY%+consumerGroup”的重试队列（这里需要注意的是，这个Topic的重试队列是针对消费组，而不是针对每个Topic设置的），用于暂时保存因为各种异常而导致Consumer端无法消费的消息。考虑到异常恢复起来需要一些时间，会为重试队列设置多个重试级别，每个重试级别都有与之对应的重新投递延时，重试次数越多投递延时就越大。RocketMQ对于重试消息的处理是先保存至Topic名称为“SCHEDULE_TOPIC_XXXX”的延迟队列中，后台定时任务按照对应的时间进行Delay后重新保存至“%RETRY%+consumerGroup”的重试队列中。

## 消息过滤

目前业界流行的消息过滤方案有以下几种：
- 基于tag的消息过滤: 一种常用的方案是基于 tag 进行消息过滤，tag 相当于对 topic 中消息再次进行逻辑分类
- 基于 sql 的消息过滤: 消息 Message 对象中添加一些自定义用户属性，消费方在消息时，可以指定一个 sql 过滤表达式
- 基于动态脚本过滤，以下两种方式，本质上都是动态脚本过滤，只不过实现策略不同：
    - DDMQ支持groovy脚本中对消息进行：过滤，修改等操作。
    - RocketMQ支持根据一个实现了MessageFilter接口的类进行消息过滤，消费者需要实现这个接口，并将源码当做订阅条件上报给rocketmq。

kafka 不具备消息过滤的能力，意味着所有的下游消费者都会接受到所有的消息。

RocketMQ 消费者可以根据 Tag 进行消息过滤，一个消息只能指定一个tag，这是因为rocketmq在存储时，将消息的tag整体内容计算出一个hashcode进行存储。消息过滤目前是在 Broker 端实现的，优点是减少了对于 Consumer 无用消息的网络传输，缺点是增加了 Broker 的负担、而且实现相对复杂。

RocketMQ 消费者支持基于自定义属性 sql 过滤。

ActiveMQ 支持基于 SQL 的消息过滤

## 消息持久化
消息中间件通常采用的几种持久化方式：
1. 持久化到数据库，例如 MySQL。
2. 持久化到 KV 存储，例如 levelDB 、伯克利 DB 等 KV 存储系统。
3. 文件记录形式持久化，例如 Kafka RocketMQ
4. 对内存数据做一个持久化镜像，例如 beanstalkd VisiNotify

1.2.3 三种持久化方式都具有将内存队列 Buffer 进行扩展的能力，4 只是一个内存的镜像，作用是当 Broker 挂掉重启后仍然能将之前内存的数据恢复出来。

JMS 与 CORBA Notification 规范没有明确说明如何持久化，但是持久化部分的性能直接决定了整个 消息中间件的性能。

RocketMQ 参考了 Kafka 的持久化方式，充分利用 Linux 文件系统内存 cache 来提高性能。

## 消息可靠性

影响消息可靠性的几种情况：
1. Broker 正常关闭
2. Broker 异常 Crash
3. OS Crash
4. 机器掉电，但是能立即恢复供电情况。
5. 机器无法开机（可能是 cpu 、主板、内存等关键设备损坏）
6. 磁盘设备损坏。

1)、2)、3)、4) 四种情况都属于硬件资源可立即恢复情况，RocketMQ在这四种情况下能保证消息不丢，或者丢失少量数据（依赖刷盘方式是同步还是异步）。

5)、6)属于单点故障，且无法恢复，一旦发生，在此单点上的消息全部丢失。RocketMQ在这两种情况下，通过异步复制，可保证99%的消息不丢，但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点，同步双写势必会影响性能，适合对消息可靠性要求极高的场合，例如与Money相关的应用。注：RocketMQ从3.0版本开始支持同步双写。

## 低延迟消息

在消息不堆积情况下，消息到达 Broker 后，能立刻到达 Consumer。

RocketMQ 使用长轮询 Pull 方式，可保证消息非常实时，消息实时性不低于 Push。

## 至少一次
至少一次(At least Once)是指每个消息必须投递一次。

RocketMQ Consumer 先 pull 消息到本地，消费完成后，才向服务器反回 ack，如果没有消费一定不会 ack 消息，所以 RocketMQ 可以很好的支持此特性。

## 仅消费一次
1. 发送消息阶段，不允许发送重复的消息
2. 消费消息阶段，不允许消费重复的消息
只有以上两个条件都满足情况下，才能认为消息是“Exactly Only Once”，而要实现以上两点，在分布式系统环境下，不可避免要产生巨大的开销。所以 RocketMQ 为了追求高性能，并不保证此特性，要求在业务上迕行去重，也就是说消费消息要做到幂等性。RocketMQ 虽然不能严格保证不重复，但是正常情况下很少会出现重复发送、消费情况，只有网络异常，Consumer 启停等异常情冴下会出现消息重复。

此问题的本质原因是网络调用存在不确定性，即既不成功也不失败的第三种状态，所以才产生了消息重复性问题。

## 回溯消费
回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能，Broker在向Consumer投递成功消息后，消息仍然需要保留。并且重新消费一般是按照时间维度，例如由于Consumer系统故障，恢复后需要重新消费1小时前的数据，那么Broker要提供一种机制，可以按照时间维度来回退消费进度。RocketMQ支持按照时间回溯消费，时间维度精确到毫秒。

## 消息堆积能力



## 事务消息

RocketMQ事务消息（Transactional Message）是指应用本地事务和发送消息操作可以被定义到全局事务中，要么同时成功，要么同时失败。RocketMQ的事务消息提供类似 X/Open XA 的分布事务功能，通过事务消息能达到分布式事务的最终一致

## 定时消息
定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的topic。 broker有配置项messageDelayLevel，默认值为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，18个level。可以配置自定义messageDelayLevel。注意，messageDelayLevel是broker的属性，不属于某个topic。发消息时，设置delayLevel等级即可：msg.setDelayLevel(level)。level有以下三种情况：

* level == 0，消息为非延迟消息
* 1<=level<=maxLevel，消息延迟特定时间，例如level==1，延迟1s
* level > maxLevel，则level== maxLevel，例如level==20，延迟2h

定时消息会暂存在名为SCHEDULE_TOPIC_XXXX的topic中，并根据delayTimeLevel存入特定的queue，queueId = delayTimeLevel – 1，即一个queue只存相同延迟的消息，保证具有相同发送延迟的消息能够顺序消费。broker会调度地消费SCHEDULE_TOPIC_XXXX，将消息写入真实的topic。

需要注意的是，定时消息会在第一次写入和调度写入真实topic时都会计数，因此发送数量、tps都会变高。

## 流量控制

生产者流控，因为broker处理能力达到瓶颈；消费者流控，因为消费能力达到瓶颈。

生产者流控：
* commitLog文件被锁时间超过osPageCacheBusyTimeOutMills时，参数默认为1000ms，返回流控。
如果开启transientStorePoolEnable == true，且broker为异步刷盘的主机，且transientStorePool中资源不足，拒绝当前send请求，返回流控。
* broker每隔10ms检查send请求队列头部请求的等待时间，如果超过waitTimeMillsInSendQueue，默认200ms，拒绝当前send请求，返回流控。
* broker通过拒绝send 请求方式实现流量控制。
注意，生产者流控，不会尝试消息重投。

消费者流控：
* 消费者本地缓存消息数超过 pullThresholdForQueue 时，默认 1000。
* 消费者本地缓存消息大小超过 pullThresholdSizeForQueue 时，默认 100 MB。
* 消费者本地缓存消息跨度超过 consumeConcurrentlyMaxSpan 时，默认 2000。

消费者流控的结果是降低拉取频率。

## 死信队列

死信队列用于处理无法被正常消费的消息。当一条消息初次消费失败，消息队列会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。

RocketMQ 将这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），将存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。在RocketMQ中，可以通过使用console控制台对死信队列中的消息进行重发来使得消费者实例再次进行消费。



## 参考文献

[RocketMQ核心特性](https://github.com/apache/rocketmq/blob/master/docs/cn/features.md)

[DDMQ](https://github.com/didi/DDMQ/blob/master/README_CN.md)