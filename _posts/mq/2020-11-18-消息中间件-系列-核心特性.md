---
layout: post
title: "MQ 系列 核心特性"
subtitle: '消息中间件基本特性'
author: "lichao"
header-img: "img/post-bg-rwd.jpg"
catalog: true
tags:
  - MQ
---

> 本文介绍消息队列 MQ 核心特性，并说明通用 MQ 中间件对这些核型特性的支持情况。

2011 年初，Linkin 开源了 Kafka 这个优秀的消息中间件，淘宝中间件团队在对 Kafka 做过充分 Review 之后，被 Kafka 无限消息堆积，高效的持久化速度吸引，但是同时发现这个消息系统主要定位于日志传输，对于使用在商品交易、订单、充值等场景下还有诸多特性不满足，为此重新用 Java 语言编写了 RocketMQ，定位于非日志的可靠消息传输。
* RocketMQ：主要应用于高可用和低延迟线上业务
* Kakfa：主要应用于高吞吐的流式任务(近在线)和离线任务

## 订阅与发布
消息发布是指某个生产者向某个 ```topic``` 发送消息；消息订阅是指某个消费者关注了某个 ```topic``` 中带有某些 ```tag``` 的消息，进而从该```topic```消费数据。

## 消息优先级（Message Priority）
消息优先级是指在一个消息队列中，每条消息都有不同的优先级，一般用整数来描述，优先级高的消息先投递，如果消息完全在一个内存队列中，那么在投递前可以按照优先级排序，令优先级高的先投递。对于优先级问题，可以归纳为两类：
1. 只要达到优先级目的即可，不是严格意义上的优先级，通常将优先级划分为高、中、低，或者再多几个级别。每个优先级用不同的 topic 表示，发消息时指定不同的 topic 来表示优先级，这种方式可以解决绝大部分的优先级问题，但是对业务中的优先级精确性做了妥协。
2. 严格优先级，优先级用整数表示，例如 ```0 ~ 65535``` ，这种优先级问题一般使用不同 topic 解决就非常不合适。

> 如果要让 MQ 支持严格优先级，会对 MQ 的性能造成非常大的影响。

#### 支持情况
由于 RocketMQ/Kafka 所有消息都是持久化的，所以如果按照优先级来排序，开销会非常大，因此 RocketMQ/Kafka 没有特意支持消息优先级，但是可以通过变通的方式实现类似功能，即单独配置一个优先级高的队列，和一个普通优先级的队列， 将不同优先级发送到不同队列即可。

RabbitMQ 支持优先级概念, 通过数字说明优先级别, 最大支持 255, 在 RabbitMQ 内部, 每个 priority 都是一个 queue, 消息根据优先级路由到相应的 queue 存储, 消费的时候, consumer 先处理完高优先级, 再处理低优先级别, 这样存在 「low priority hungry」 的问题. 

> 问题：如何实现支持优先级的Consumer：
> [Kafka 优先级队列](https://qiankunli.github.io/2019/04/27/kafka_priority.html)
> [Kafka 优先级支持](https://www.menina.cn/article/103)
> [Azure 优先级队列设计模式](https://docs.microsoft.com/zh-cn/azure/architecture/patterns/priority-queue)

## 消息顺序（Message Order）
消息有序指的是一类消息消费时，能按照发送的顺序来消费。例如：一个订单产生了三条消息分别是订单创建、订单付款、订单完成。消费时要按照这个顺序消费才有意义，但是同时订单之间是可以并行消费的。
顺序消息分为全局顺序消息与分区顺序消息，全局顺序是指某个 Topic 下的所有消息都要保证顺序；分区顺序消息只要保证每一组消息被顺序消费即可。

三种消息的类型介绍如下： 
* 普通消息：消息是无序的，任意发送到哪一个队列都可以。 
* 普通有序消息：同一类消息(例如某个用户的消息)总是发送到同一个队列，在异常情况下，也可以发送到其他队列。
* 严格有序消息：消息必须被发送到同一个队列，即使在异常情况下，也不允许发送到其他队列。 
#### 支持情况
* Kafka 支持消息顺序，但是一台代理宕机后，就会产生消息乱序。所有消息根据 sharding key 进行分区。同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。sharding key 是顺序消息中用来区分不同分区的关键字段，和普通消息的 key 是完全不同的概念。 适用于性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。
* RocketMQ 支持普通/严格有序消息。在严格顺序消息场景下，一台 Broker 宕机后，发送消息会失败，但是不会乱序。

> MySQL 的二进制日志分发需要严格的消息顺序

对于这三种类型的消息，RocketMQ 分别提供了对应的方法来发送消息，例如同步发送API(异步/批量/oneway也是类似)： 
![有序消息发送](/img/rocketmq/有序消息发送.png)

> 需要注意的是：
>> 这些方法重载形式，本意是为了支持以上三种不同的消息类型。但是不按套路出牌，例如：对于一个用户的多条消息，在调用第一种send方法形式时，依然在对于同一个用户每次发送消息时，选择了不同的队列(MessageQueue)，那么也没有人能阻止。这就忽略了 RocketMQ 团队设计这三个方法的意图。 
>> RocketMQ 客户端的生产者重试机制，只会普通消息有作用。对于普通有序消息、严格有序消息是没有作用。

## 消息重投
**对于普通消息，消息发送默认采用 round-robin 机制来选择发送到哪一个队列，如果发送失败，默认重试 2 次。对于普通有序消息，RocketMQ 是不会进行重试的。如果需要重试，那么业务 RD 同学需要自己编写重试代码，例如通过一个 for 循环，最多重试几次。对于严格有序消息，由于直接指定了一个 MessageQueue。如果这个 MessageQueue 所在的 Broker 宕机了，那么之后的重试必然都失败。**

**生产者在发送消息时，同步消息失败会重投，异步消息有重试，oneway 没有任何保证。**消息重投保证消息尽可能发送成功、不丢失，但可能会造成消息重复，消息重复在RocketMQ中是无法避免的问题。消息重复在一般情况下不会发生，当出现消息量大、网络抖动，消息重复就会是大概率事件。另外，生产者主动重发、consumer负载变化也会导致重复消息。如下方法可以设置消息重试策略：
* retryTimesWhenSendFailed: 同步发送失败重投次数，默认为2，因此生产者会最多尝试发送retryTimesWhenSendFailed + 1次。不会选择上次失败的broker，尝试向其他broker发送，最大程度保证消息不丢。超过重投次数，抛出异常，由客户端保证消息不丢。当出现RemotingException、MQClientException和部分MQBrokerException时会重投。
* retryTimesWhenSendAsyncFailed: 异步发送失败重试次数，异步重试不会选择其他broker，仅在同一个broker上做重试，不保证消息不丢。
* retryAnotherBrokerWhenNotStoreOK: 消息刷盘（主或备）超时或slave不可用（返回状态非SEND_OK），是否尝试发送到其他 broker，默认false。十分重要消息可以开启。

## 消费重试
Consumer消费消息失败后，要提供一种重试机制，令消息再消费一次。Consumer消费消息失败通常可以认为有以下几种情况：

* 由于消息本身的原因，例如反序列化失败，消息数据本身无法处理（例如话费充值，当前消息的手机号被注销，无法充值）等。这种错误通常需要跳过这条消息，再消费其它消息，而这条失败的消息即使立刻重试消费，99%也不成功，所以最好提供一种定时重试机制，即过10秒后再重试。
* 由于依赖的下游应用服务不可用，例如db连接不可用，外系统网络不可达等。遇到这种错误，即使跳过当前失败的消息，消费其他消息同样也会报错。这种情况建议应用sleep 30s，再消费下一条消息，这样可以减轻Broker重试消息的压力。

RocketMQ会为每个消费组都设置一个Topic名称为“%RETRY%+consumerGroup”的重试队列（这里需要注意的是，这个Topic的重试队列是针对消费组，而不是针对每个Topic设置的），用于暂时保存因为各种异常而导致Consumer端无法消费的消息。考虑到异常恢复起来需要一些时间，会为重试队列设置多个重试级别，每个重试级别都有与之对应的重新投递延时，重试次数越多投递延时就越大。RocketMQ对于重试消息的处理是先保存至Topic名称为“SCHEDULE_TOPIC_XXXX”的延迟队列中，后台定时任务按照对应的时间进行Delay后重新保存至“%RETRY%+consumerGroup”的重试队列中。
####  消费失败重试
* Kafka 消费失败不支持重试。
* RocketMQ 消费失败支持定时重试，每次重试间隔时间顺延 
## 死信队列
死信队列用于处理无法被正常消费的消息。当一条消息初次消费失败，消息队列会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。

RocketMQ 将这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），将存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。在RocketMQ中，可以通过使用console控制台对死信队列中的消息进行重发来使得消费者实例再次进行消费。

## 消息过滤

目前业界流行的消息过滤方案有以下几种：
- 基于 tag 的消息过滤: 一种常用的方案是基于 tag 进行消息过滤，tag 相当于对 topic 中消息再次进行逻辑分类
- 基于 sql 的消息过滤: 消息 Message 对象中添加一些自定义用户属性，消费方在消息时，可以指定一个 sql 过滤表达式
- 基于动态脚本过滤，以下两种方式，本质上都是动态脚本过滤，只不过实现策略不同：
    - DDMQ支持groovy脚本中对消息进行：过滤，修改等操作。
    - RocketMQ支持根据一个实现了MessageFilter接口的类进行消息过滤，消费者需要实现这个接口，并将源码当做订阅条件上报给rocketmq。

kafka 不具备消息过滤的能力，意味着所有的下游消费者都会接受到所有的消息。

RocketMQ 消费者可以根据 Tag 进行消息过滤，一个消息只能指定一个tag，这是因为rocketmq在存储时，将消息的tag整体内容计算出一个hashcode进行存储。消息过滤目前是在 Broker 端实现的，优点是减少了对于 Consumer 无用消息的网络传输，缺点是增加了 Broker 的负担、而且实现相对复杂。

RocketMQ 消费者支持基于自定义属性 sql 过滤。

ActiveMQ 支持基于 SQL 的消息过滤
#### 消息过滤
* 不支持代理端的消息过滤
* RocketMQ支持两种代理端消息过滤方式
  * 根据消息变量来过滤，相当于子主题概念
  * 向服务器上传一段Java代码，可以对消息做任意形式的过滤，甚至可以做Message身体的过滤拆分。
## 消息持久化
消息中间件通常采用的几种持久化方式：
1. 持久化到数据库，例如 MySQL。
2. 持久化到 KV 存储，例如 levelDB 、伯克利 DB 等 KV 存储系统。
3. 文件记录形式持久化，例如 Kafka RocketMQ
4. 对内存数据做一个持久化镜像，例如 beanstalkd VisiNotify

1.2.3 三种持久化方式都具有将内存队列 Buffer 进行扩展的能力，4 只是一个内存的镜像，作用是当 Broker 挂掉重启后仍然能将之前内存的数据恢复出来。

JMS 与 CORBA Notification 规范没有明确说明如何持久化，但是持久化部分的性能直接决定了整个 消息中间件的性能。

RocketMQ 参考了 Kafka 的持久化方式，充分利用 Linux 文件系统内存 cache 来提高性能。

#### 性能对比

* Kafka 单机写入 TPS 约在百万条/秒，消息大小10个字节
* RocketMQ 单机写入 TPS: 单实例约 7 万条/秒，单机部署 3 个 Broker，可以跑到最高12万条/秒，消息大小10个字节

总结：Kafka的 TPS 跑到单机百万，主要是由于 Producer 端将多个小消息合并，批量发向 Broker。

> RocketMQ 为什么不支持 Producer 端将多个小消息合并？
1. Producer 通常使用的 Java 语言，缓存过多消息，GC 是个很严重的问题
2. Producer 调用发送消息接口，消息未发送到Broker，向业务返回成功，此时 Producer 宕机，会导致消息丢失，业务出错
3. Producer 通常为分布式系统，且每台机器都是多线程发送，我们认为线上的系统单个 Producer 每秒产生的数据量有限，不可能上万。
4. 缓存的功能完全可以由上层业务完成。
  

#### 单机支持的队列数
* Kafka单机超过 64 个队列/分区，Load 会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长。Kafka分区数无法过多的问题
* RocketMQ单机支持最高5万个队列，负载不会发生明显变化

> 队列多有什么好处？
1. 单机可以创建更多 topic，因为每个主题都是由一批队列组成
2. 消费者的集群规模和队列数成正比，队列越多，消费类集群可以越大

#### 数据可靠性
* RocketMQ 支持异步刷盘，同步刷盘，同步复制，异步复制
* Kafka 使用异步刷盘方式，异步复制/同步复制

> 总结：RocketMQ 的同步刷盘在单机可靠性上比 Kafka 更高，不会因为操作系统 Crash，导致数据丢失。Kafka 同步 Replication 理论上性能低于 RocketMQ 的同步 Replication，原因是 Kafka 的数据以分区为单位组织，意味着一个 Kafka 实例上会​​有几百个数据分区，RocketMQ 一个实例上只有一个数据分区，RocketMQ 可以充分利用 IO 组 Commit 机制，批量传输数据，配置同步 Replication 与异步 Replication 相比，性能损耗约 20%~30%.


## 消息可靠性

影响消息可靠性的几种情况：
1. Broker 正常关闭
2. Broker 异常 Crash
3. OS Crash
4. 机器掉电，但是能立即恢复供电情况。
5. 机器无法开机（可能是 cpu 、主板、内存等关键设备损坏）
6. 磁盘设备损坏。

1)、2)、3)、4) 四种情况都属于硬件资源可立即恢复情况，RocketMQ在这四种情况下能保证消息不丢，或者丢失少量数据（依赖刷盘方式是同步还是异步）。

5)、6)属于单点故障，且无法恢复，一旦发生，在此单点上的消息全部丢失。RocketMQ在这两种情况下，通过异步复制，可保证99%的消息不丢，但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点，同步双写势必会影响性能，适合对消息可靠性要求极高的场合，例如与Money相关的应用。注：RocketMQ从3.0版本开始支持同步双写。

## 消息投递实时性
* Kafka使用短轮询方式，实时性取决于轮询间隔时间，0.8以后版本支持长轮询。
* RocketMQ使用长轮询，同Push方式实时性一致，消息的投递延时通常在几个毫秒。

在消息不堆积情况下，消息到达 Broker 后，能立刻到达 Consumer。

RocketMQ 使用长轮询 Pull 方式，可保证消息非常实时，消息实时性不低于 Push。

## 至少一次
至少一次(At least Once)是指每个消息必须投递一次。

RocketMQ Consumer 先 pull 消息到本地，消费完成后，才向服务器反回 ack，如果没有消费一定不会 ack 消息，所以 RocketMQ 可以很好的支持此特性。

## 仅消费一次
1. 发送消息阶段，不允许发送重复的消息
2. 消费消息阶段，不允许消费重复的消息
只有以上两个条件都满足情况下，才能认为消息是“Exactly Only Once”，而要实现以上两点，在分布式系统环境下，不可避免要产生巨大的开销。所以 RocketMQ 为了追求高性能，并不保证此特性，要求在业务上迕行去重，也就是说消费消息要做到幂等性。RocketMQ 虽然不能严格保证不重复，但是正常情况下很少会出现重复发送、消费情况，只有网络异常，Consumer 启停等异常情冴下会出现消息重复。

此问题的本质原因是网络调用存在不确定性，即既不成功也不失败的第三种状态，所以才产生了消息重复性问题。

## 回溯消费
回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能，Broker在向Consumer投递成功消息后，消息仍然需要保留。并且重新消费一般是按照时间维度，例如由于Consumer系统故障，恢复后需要重新消费1小时前的数据，那么Broker要提供一种机制，可以按照时间维度来回退消费进度。RocketMQ支持按照时间回溯消费，时间维度精确到毫秒。

#### 消息回溯
* Kafka 理论上可以按照偏移来回溯消息
* RocketMQ 支持按照时间来回溯消息，精度毫秒，例如从一天之前的某时某分某秒开始重新消费消息

#### 消息查询
* Kafka 不支持消息查询
* RocketMQ 支持根据消息标识查询消息，也支持根据消息内容查询消息（发送消息时指定一个消息密钥，任意字符串，例如指定为订单编号）


## 消息堆积能力
理论上Kafka要比RocketMQ的堆积能力更强，不过RocketMQ单机也可以支持亿级的消息堆积能力，我们认为这个堆积能力已经完全可以满足业务需求。

## 事务消息
RocketMQ 事务消息（Transactional Message）是指应用本地事务和发送消息操作可以被定义到全局事务中，要么同时成功，要么同时失败。RocketMQ的事务消息提供类似 X/Open XA 的分布事务功能，通过事务消息能达到分布式事务的最终一致

#### 分布式事务消息
* Kafka 不支持分布式事务消息
* 阿里云MQ支持分布式事务消息，未来开源版本的RocketMQ也有计划支持分布式事务消息

## 定时消息
* Kafka 不支持定时消息
* RocketMQ支持两类定时消息
  * 开源版本RocketMQ仅支持定时级别，定时级用户可定制
  * 阿里云MQ指定的毫秒级别的延时时间

定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的topic。 broker有配置项messageDelayLevel，默认值为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，18个level。可以配置自定义messageDelayLevel。注意，messageDelayLevel是broker的属性，不属于某个topic。发消息时，设置delayLevel等级即可：msg.setDelayLevel(level)。level有以下三种情况：

* level == 0，消息为非延迟消息
* 1<=level<=maxLevel，消息延迟特定时间，例如level==1，延迟1s
* level > maxLevel，则level== maxLevel，例如level==20，延迟2h

定时消息会暂存在名为SCHEDULE_TOPIC_XXXX的topic中，并根据delayTimeLevel存入特定的queue，queueId = delayTimeLevel – 1，即一个queue只存相同延迟的消息，保证具有相同发送延迟的消息能够顺序消费。broker会调度地消费SCHEDULE_TOPIC_XXXX，将消息写入真实的topic。

需要注意的是，定时消息会在第一次写入和调度写入真实topic时都会计数，因此发送数量、tps都会变高。

## 流量控制

生产者流控，因为broker处理能力达到瓶颈；消费者流控，因为消费能力达到瓶颈。

生产者流控：
* commitLog文件被锁时间超过osPageCacheBusyTimeOutMills时，参数默认为1000ms，返回流控。
如果开启transientStorePoolEnable == true，且broker为异步刷盘的主机，且transientStorePool中资源不足，拒绝当前send请求，返回流控。
* broker每隔10ms检查send请求队列头部请求的等待时间，如果超过waitTimeMillsInSendQueue，默认200ms，拒绝当前send请求，返回流控。
* broker通过拒绝send 请求方式实现流量控制。
注意，生产者流控，不会尝试消息重投。

消费者流控：
* 消费者本地缓存消息数超过 pullThresholdForQueue 时，默认 1000。
* 消费者本地缓存消息大小超过 pullThresholdSizeForQueue 时，默认 100 MB。
* 消费者本地缓存消息跨度超过 consumeConcurrentlyMaxSpan 时，默认 2000。

消费者流控的结果是降低拉取频率。

#### 消费并行度
* Kafka的消费并行度依赖Topic配置的分区数，如分区数为10，那么最多10台机器来并行消费（每台机器只能开启一个线程），或者一台机器消费（10个线程并行消费）。即消费并行度和分区数一致。

* RocketMQ消费并行度分两种情况
  * 顺序消费方式并行度同卡夫卡完全一致
  * 乱序方式并行度取决于Consumer的线程数，如Topic配置10个队列，10台机器消费，每台机器100个线程，那么并行度为1000。

#### 消息轨迹
* Kafka不支持消息轨迹
* 阿里云MQ支持消息轨迹


## 架构设计对比
#### Namesrv VS zk
Kafka 通过 zookeeper 来进行协调，而rocketMq通过自身的namesrv进行协调。

RocketMQ 在协调节点的设计上显得更加轻量，用了另外一种方式解决高可用的问题，思路也是可以借鉴的。

> Kafka 具备选举功能，在Kafka里面，Master/Slave的选举，有2步：第1步，先通过ZK在所有机器中，选举出一个KafkaController；第2步，再由这个Controller，决定每个partition的Master是谁，Slave是谁。因为有了选举功能，所以kafka某个partition的master挂了，该partition对应的某个slave会升级为主对外提供服务。

> RocketMQ 不具备选举，Master/Slave 的角色也是固定的。当一个 Master 挂了之后，你可以写到其他 Master 上，但不能让一个 Slave 切换成 Master。那么 RocketMQ 是如何实现高可用的呢，其实很简单，RocketMQ 的所有broker节点的角色都是一样，上面分配的 topic 和对应的 queue 的数量也是一样的，Mq只能保证当一个broker挂了，把原本写到这个broker的请求迁移到其他 broker 上面，而并不是这个 broker 对应的 slave 升级为主。

## 参考文献

[RocketMQ核心特性](https://github.com/apache/rocketmq/blob/master/docs/cn/features.md)

[DDMQ](https://github.com/didi/DDMQ/blob/master/README_CN.md)

[引用自](http://jm.taobao.org/2016/03/24/rmq-vs-kafka/)

[引用自](https://www.jianshu.com/p/c474ca9f9430)
