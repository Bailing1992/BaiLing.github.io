---
layout: post
title: "Kafka 系列 消费者(Java)"
subtitle: '深入理解Kafka'
author: "lichao"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
  - Kafka
---

本文主要介绍目前流行的新消费者（Java 语言编写的）客户端


一个正常的消费逻辑需要具备以下几个步骤：
1. 配置消费者客户端参数及创建相应的消费者实例。
2. 订阅主题。
3. 拉取消息并消费。
4. 提交消费位移。
5. 关闭消费者实例。
## 订阅主题
Kafka同一个消费组可以同时订阅多个主题

## 拉取消息
Kafka 中的消费是基于拉模式的。消息的消费一般有两种模式：推模式和拉模式。推模式是服务端主动将消息推送给消费者，而拉模式是消费者主动向服务端发起请求来拉取消息。
## 提交位移

对于 Kafka 中的分区而言，它的每条消息都有唯一的 offset，用来表示消息在分区中对应的位置。对于消费者而言，它也有一个 offset 的概念，消费者使用 offset 来表示消费到分区中某个消息所在的位置。

在旧消费者客户端中，消费位移是存储在 ZooKeeper 中的。而在新消费者客户端中，消费位移存储在 Kafka 内部的主题 consumer offsets 中。这里把将消费位移存储起来（持久化）的动作称为“提交’，消费者在消费完消息之后需要执行消费位移的提交。
![消费位移](/img/mq/kafka/消费位移.png){:height="80%" width="80%"}
消费位移 x 表示某一次拉取操作中此分区消息的最大偏移量，假设当前消费者已经消费了x 位置的消息，那么就可以说消费者的消费位移为 x ，图中也用了 lastConsumedOffset 这个单词来标识它。
**当前消费者需要提交的消费位移是下一条需要拉取的消息的位置，对应于图中的 position**

在消费者中还有一个 committed offset 的概念，它表示已经提交过的消费位移。
#### 自动位移提交
在默认的方式下，消费者每隔 5 秒会将拉取到的每个分区中最大的消息位移进行提交。自动位移提交的动作是在 poll（）方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交，如果可以，那么就会提交上一次轮询的位移。自动位移提交也无法做到精确的位移管理。自动提交消费位移的方式会带来重复消费和消息丢失的问题，出现消息丢失的原因是自动位移提交不会判断消息是否被业务处理，可以理解为拉取\提交消息线程和业务处理线程独立运行。
#### 手动位移提交
如果业务处理完成才能认为消息被成功消费，手动的提交方式可以让开发人员根据程序的逻辑在合适的地方进行位移提交。手动提交就避免消息丢失，不能避免消息重复。

手动提交可以细分为同步提交和异步提交，对应于 KafkaConsumer 中的 commitSync（）和 commitAsync（）两种类型的方法。

###### 同步提交
同步提交有重复消费的问题，如果在业务逻辑处理完之后，并且在同步位移提交前，程序出现了崩渍，那么待恢复之后又只能从上一次位移提交的地方拉取消息，由此在两次位移提交的窗口中出现了重复消费的现象。
```
while（isRunning.get()) {
  ConsumerRecords<String, String> records= consumer.poll(1000);
  for (ConsumerRecord<String, String> record : records) {
    //do some logical processing.
  }
  consumer.commitSync();
}
```
commitSync（）方法会根据 poll（）方法拉取的最新位移来进行提交。只要没有发生不可恢复的错误（ Unrecoverable Eηor ），它就会阻塞消费者线程直至位移提交完成。对于不可恢复的错误，比如 CommitFailedException 、WakeupException 、InterruptException 、AuthenticationException 、AuthorizationException 等，可以将其捕获并做针对性的处理。

对于采用 commitSync（）的无参方法而言，它提交消费位移的频率和拉取批次消息、处理批次消息的频率是一样的，如果想寻求更细粒度的、更精准的提交，那么就需要使用commitSync()的另一个含参方法，具体定义如下：
```
public void commitSync(final Map<TopicPartition , OffsetAndMetadata> offsets)
```

该方法提供了一个 offsets 参数，用来提交指定分区的位移。无参的 commitSync（）方法只能提交当前批次对应的 position 值。如果需要提交一个中间值，比如业务每消费一条消息就提交一次位移，那么就可以使用这种方式。

###### 异步提交
在一般情况下，位移提交失败的情况很少发生，不重试也没有关系，后面的提交也会有成功的。重试会增加代码逻辑的复杂度，不重试会增加重复消费的概率。如果消费者异常退出，那么这个重复消费的问题就很难避免，因为这种情况下无法及时提交消费位移；如果消费者正常退出或发生再均衡的情况，那么可以在退出或再均衡执行之前使用同步提交的方式做最后的把关。

#### 默认位移
在 Kafka 中每当消费者查找不到所记录的消费位移时，就会根据消费者客户端参数 ```auto.offset.reset``` 的配置来决定从何处开始进行消费，这个参数的默认值为```latest```，表示从分区末尾开始消费消息。如果将 ```auto.offset.reset``` 参数配置为 ```earliest```，那么消费者会从起始处，也就是 0 开始消费。

```auto.offset.reset``` 参数还有一个可配置的值```none```，配置为此值就意味着出现查到不到消费位移的时候，既不从最新的消息位置处开始消费，也不从最早的消息位置处开始消费，此时会报出```NoOffsetForPartitionException``` 异常。

> 除了查找不到消费位移，位移越界也会触发 ```auto.offset.reset``` 参数的执行

## 再平衡
再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。

不过在再均衡发生期间，消费组内的消费者是无法读取消息的。也就是说，在再均衡发生期间的这一小段时间内，消费组会变得不可用。另外，当一个分区被重新分配给另一个消费者时，消费者当前的状态也会丢失。比如消费者消费完某个分区中的一部分消息时还没有来得及提交消费位移就发生了再均衡操作，之后这个分区又被分配给了消费组内的另一个消费者，原来被消费完的那部分消息又被重新消费一遍，也就是发生了重复消费。一般情况下，应尽量避免不必要的再均衡的发生。

## 线程模型
![消费者线程模型](/img/mq/kafka/消费者线程模型.png){:height="80%" width="80%"}
通过多线程的方式来实现消息消费，多线程的目的就是为了提高整体的消费能力。多线程的实现方式有多种，最常见的方式：线程封闭，即为每个线程实例化一个 KafkaConsumer 对象（KafkaConsumer 却是非线程安全的）。**一般而言，分区是消费线程的最小划分单位。**
一个线程对应一个 KafkaConsumer 实例，可以称之为消费线程。一个消费线程可以消费一个或多个分区中的消息，所有的消费线程都隶属于同一个消费组。这种实现方式的并发度受限于分区的实际个数，当消费线程的个数大于分区数时，就有部分消费线程一直处于空闲的状态。

这种多线程的实现方式和开启多个消费进程的方式没有本质上的区别，它的优点是每个线程可以按顺序消费各个分区中的消息。缺点也很明显，每个消费线程都要维护一个独立的 TCP 连接， 如果分区数和consumerThreadNum 的值都很大，那么会造成不小的系统开销。

#### 第二种线程模型
第二种方式是多个消费线程同时消费同一个分区，这个通过```assign（）```、```seek（）```等方法实现，这样可以打破原有的消费线程的个数不能超过分区数的限制，进一步提高了消费的能力。不过这种实现方式对于位移提交和顺序控制的处理就会变得非常复杂，实际应用中使用得极少。

#### 第三种线程模型

对于方法一而言，如果对消息的处理非常迅速，那么 ```poll（）```拉取的频次也会更高，进而整体消费的性能也会提升。相反，如果对消息的处理缓慢，比如进行一个事务性操作，或者等待一个 RPC 的同步响应，那么```poll（）```拉取的频次也会随之下降，进而造成整体消费性能的下降。一般而言，```poll（）``` 拉取消息的速度是相当快的，而整体消费的瓶颈也正是在处理消息这一块，如果我们通过－定的方式来改进这一部分，那么我们就能带动整体消费性能的提升。考虑第三种实现方式，将处理消息模块改成多线程的实现方式。
![第三种消费者线程模型](/img/mq/kafka/第三种消费者线程模型.png){:height="80%" width="80%"}
第三种实现方式相比第一种实现方式而言，除了横向扩展的能力，还可以减少TCP 连接对系统资源的消耗，不过缺点就是对于消息的顺序处理就比较困难了。

每一个处理消息的 RecordHandler 类在处理完消息之后都将对应的消费位移保存到共享变量 offsets 中， KafraConsumerThread 在每一次 ```poll（）```方法之后都读取 offsets 中的内容并对其进行位移提交。注意在实现的过程中对 offsets 读写需要加锁处理，防止出现并发问题。井且在写入 offsets 的时候需要注意位移覆盖的问题。

其实这种位移提交的方式会有数据丢失的风险。对于同一个分区中的消息，假设一个处理线程 RecordHandler1 正在处理 offset 为 ```0～99``` 的消息，而另一个处理线程 RecordHandler2 已经处理完了offset 为 ```100～199``` 的消息并进行了位移提交，此时如果 RecordHandler1 发生异常，则之后的消费只能从 200 开始而无法再次消费 ```0～99``` 的消息，从而造成了消息丢失的现象。

#### 第四种线程模型

基于滑动窗口实现，这里的滑动窗口式的实现方式是将拉取到的消息暂存起来，多个消费线程可以拉取暂存的消息，这个用于暂存消息的缓存大小即为滑动窗口的大小，总体上而言没有太多的变化，不同的是对于消费位移的把控。

![第四种消费者线程模型](/img/mq/kafka/第四种消费者线程模型.png){:height="70%" width="70%"}

每一个方格代表一个批次的消息，一个滑动窗口包含若干方格， startOffset 标注的是当前滑动窗口的起始位置， endOffset 标注的是末尾位置。每当 startOffset 指向的方格中的消息被消费完成，就可以提交这部分的位移，与此同时，窗口向前滑动一格，删除原来 startOffset 所指方格中对应的消息，并且拉取新的消息进入窗口。滑动窗口的大小固定，所对应的用来暂存消息的缓存大小也就固定了，这部分内存开销可控。方格大小和滑动窗口的大小同时决定了消费线程的并发数： 一个方格对应一个消费线程，对于窗口大小固定的情况，方格越小并行度越高：对于方格大小固定的情况，窗口越大并行度越高。不过，若窗口设置得过大，不仅会增大内存的开销，而且在发生异常（比如Crash ）的情况下也会引起大量的重复消费，同时还考虑线程切换的开销， 建议根据实际情况设置一个合理的值，不管是对于方格还是窗口而言，过大或过小都不合适。

如果一个方格内的消息无法被标记为消费完成，那么就会造成startOffset 的悬停。为了使窗口能够继续向前滑动， 那么就需要设定一个闹值，当startOffset 悬停一定的时间后就对这部分消息进行本地重试消费，如果重试失败就转入重试队列，如果还不奏效就转入死信队列。