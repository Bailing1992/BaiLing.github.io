---
layout: post
title: "Mongo 高可用"
subtitle: '开启 MongoDB 学习新篇章'
author: "lichao"
header-img: "img/post-bg-rwd.jpg"
catalog: true
tags:
  - mongo 
---

> 高可用性 HA（High Availability）指的是缩短因正常运维或者非预期故障而导致的停机时间，提高系统可用性。大白话就是，无论出啥事都不能让承载的业务受影响，这就是高可用。无论是数据的高可靠，还是组件的高可用全都是一个解决方案：冗余。通过多个组件和备份导致对外提供一致性和不中断的服务。冗余是根本，但是怎么使用冗余则各有不同。



## MongoDB高可用
MongoDB 高可用方案分两种 ：
* Master-Slave主从复制
* Replica Sets 复制集

Replica Sets 的结构非常类似一个集群 ，其中一个节点如果出现故障, 其它节点马上会将业务 接过来而无须停机操作。

## Master-Slave 模式
Mongodb 提供的第一种冗余策略就是 Master-Slave 策略，这个也是分布式系统最开始的冗余策略，这种是一种热备策略。Master-Slave 由主从角色构成：
* Master(主): 可读可写，当数据有修改的时候，会将 Oplog 同步到所有连接的 Slave 上去。
* Slave(从): 只读，所有的 Slave 从 Master 同步数据，从节点与从节点之间不感知。
Master-Slave 架构一般用于备份或者做读写分离，一般是一主一从设计和一主多从设计。

主从模式存在的问题：
* 数据不一致: Master 节点可以写，Slave 节点只能同步 Master 数据并对外提供读服务，这是异步的过程。
* 可用性差：主节点挂掉后，需要人为操作处理把 slave 节点切换成 master 节点。是一个巨大的停服窗口。

MongoDB 3.6 起已不推荐使用主从模式，自 MongoDB 3.2 起，分片群集组件已弃用主从复制。因为 Master-Slave 其中 Master 宕机后不能自动恢复，只能靠人为操作，可靠性也差，操作不当就存在丢数据的风险。

## Replica Set 副本集模式

在 MongoDB 中，创建一个副本集之后就可以使用复制功能了。副本集是一组服务器，其中有一个主服务器(primary），用于处理客户端请求，还有多个备份服务器（secondary），用于保存主服务器的数据副本。如果主服务器崩溃了，备份服务器会自行将其中一个成员升级为新的主服务器。

在副本集中，写操作必须在主节点执行，不能对备份节点执行写操作。备份节点只能通过复制功能写入数据，不接受客户端的写入请求。

默认情况下，客户端不能从备份节点中读取数据。在备份节点上显式地执行setSlaveOk之后，客户端就可以从备份节点中读取数据了。

Replica Sets 的结构非常类似一个集群 ，其中一个节点如果出现故障, 其它节点马上会将业务 接过来而无须停机操作。

#### 操作配置
下面依次执行创建副本集、使用副本集和关闭副本集的操作。
1. 使用 ```--nodb``` 选项启动一个 mongo shell，这样可以启动shell但是不连接到任何的mongod。
   ```shell
   $mongo --nodb
   ```
2. 创建一个副本集，其中包含三个服务器的副本集：一个主服务器和两个备份服务器。
   ```shell
   > replSet = new ReplSetTest({"nodes":3}) 
   ```
3. 启动三个 mongod 进程
   ```shell
   // 启动 3 个 mongod 进程
   > replSet.startSet()
   // 配置复制功能
   > replSet.initiate()
   ```
4. 在第二个 shell 中，连接到运行在第一个端口的 mongod，即连接到一个副本集成员。
   ```shell
   $mongo --port 20000
   ```
5. 执行 isMaster命令，查看副本集状态。
   ```shell
   > db.isMaster()
   {
     "isMaster": true,
     "hosts": [
       ...:20000,
       ...:20001,
       ...:20002
     ]
   }
   ```
6. 主节点上执行写入操作:
    ```shell
   > db.blog.insert({"title":"hello, world!!"})
  
   ```
7. 在另一个 shell 中，连接一个备份节点
   ```shell
   $mongo --port 20001
   ```
8. 在备份节点上执行查找操作
   ```shell
   > db.blog.find()

   Error: error: { "ok" : 0, "errmsg" : "not master and slaveOk=false", "code" : 13435 }
   ```
9. 设置允许从备份节点读取数据，即使是过期数据，注意setSlaveOk是对连接设置的，而不是对数据库设置的
   ```shell
   > db.setSlaveOk()

   > db.blog.find()
   {"title":"hello, world!!"}
   ```
10. 不能对备份节点执行写操作
    ```shell
    > db.bolg.insert({"title":"hello, world"})

    WriteResult({ "writeError" : { "code" : 10107, "errmsg" : "not master" } })
    ```
11. 在第一个 shell 中执行副本集关闭
    ```shell
    > replSet.stopSet()

    ReplSetTest stopSet Shut down repl set - test worked 
    ``` 
### 原理
备份节点可能会落后于主机点，可能没有最新写入的数据，所有备份节点在默认情况下会拒绝读取请求，以防应用程序意外拿到过期的数据。

#### 同步
> 复制用于在多台服务器之间备份数据。

MongoDB 的复制功能是使用操作日志 oplog 实现的，操作日志包含了主节点的每一次写操作。oplog 是主节点的 local 数据库中的一个固定集合。备份节点通过查询这个集合就可以知道需要进行复制的操作。

每个备份节点都维护着自己的 oplog，记录着每一次从主节点复制数据的操作。这样，每个成员都可以作为同步源提供给其他成员使用。备份节点从当前使用的同步源中获取需要执行的操作，然后在自己的数据集上执行这些操作，最后再将这些操作写入自己的 oplog。

> 由于复制操作的过程是先复制数据再写入 oplog，所以，备份节点可能会在已经同步过的数据上再次执行复制操作。MongoDB 保证将 oplog 中的同一个操作执行多次，与只执行一次的效果是一样的。

oplog 大小是固定的，只能保存特定数量的操作日志，oplog 操作的维度是文档，即如果单个操作影响多个文档，那么每个受影响的文档都会对应 oplog 中的一条日志。如果执行大量的批量操作，oplog 很快就会被填满。

###### 判断全量同步及增量同步
由于 oplog 大小是固定的，当从库加入到副本集的时候，就会检查自身状态，确定是否可以从某个成员那里进行增量同步。如果不行就需要从某个成员那里进行完整的数据复制，即 Initial Syc（全量同步）。

1. 如果 local 数据库中的 oplog.rs 集合是空的，则做全量同步。
2. 如果 minValid 集合里面存储的是 _initialSyncFlag，则做全量同步（用于 init sync 失败处理）
3. 如果 initialSyncRequested 是 true，则做全量同步（用于 resync 命令，resync 命令只用于 master/slave 架构，副本集无法使用）

以上三个条件有一个条件满足就需要做全量同步。

###### 全量同步

> MongoDB 默认是采取级联复制的架构，就是默认不一定选择主库作为自己的同步源，如果不想让其进行级联复制，可以通过 chainingAllowed 参数来进行控制。在级联复制的情况下，你也可以通过 replSetSyncFrom 命令来指定你想复制的同步源。所以这里说的同步源其实相对于从库来说就是它的主库。

1. 从库会在副本集其他节点通过以下条件筛选符合自己的同步源。通过下述筛选最后过滤出来的节点作为新的同步源。
   * 如果设置了 chainingAllowed 为 false，那么只能选取主库为同步源
   * 找到与自己 ping 时间最小的并且数据比自己新的节点（在副本集初始化的时候，或者新节点加入副本集的时候，新节点对副本集的其他节点至少 ping 两次）
   * 该同步源与主库最新 optime 做对比，如果延迟主库超过 30s，则不选择该同步源。
   * 在第一次的过滤中，首先会淘汰比自己数据还旧的节点。如果第一次没有，那么第二次需要算上这些节点，防止最后没有节点可以做为同步源了。
   * 最后确认该节点是否被禁止参与选举，如果是则跳过该节点。
2. 删除 MongoDB 中除 local 以外的所有数据库
3. 拉取主库存量数据，即将同步源的所有记录全部复制到本地
   ![增量复制](/img/mongodb/全量配置.png)
   1. Add _initialSyncFlag to minValid collection to tell us to restart initial sync if we crash in the middle of this procedure
   2. Record start time.（记录当前主库最近一次 oplog time）
   3. Clone.
   4. Set minValid1 to sync target’s latest op time.
   5. Apply ops from start to minValid1, fetching missing docs as needed.（Apply Oplog 1）
   6. Set minValid2 to sync target’s latest op time.
   7. Apply ops from minValid1 to minValid2.（Apply Oplog 2）
   8. Build indexes.
   9. Set minValid3 to sync target’s latest op time.
   10. Apply ops from minValid2 to minValid3.（Apply Oplog 3）
   11. Cleanup minValid collection: remove _initialSyncFlag field, set ts to minValid3 OpTime


> Mongo 3.4 Initial Sync在创建的集合的时候同时创建了索引（与主库一样），在 MongoDB 3.4 版本之前只创建 _id 索引，其他索引等待数据 copy 完成之后进行创建。

###### 增量同步

在完成 Initial Sync后，就是已经把同步源的存量数据拿过来了，主库后续写入的数据通过增量同步的方式进行同步。
![增量复制](/img/mongodb/增量复制.png)
注：这里不一定是 Primary，同步源也可能是 Secondary。

我们可以看到上述有 6 个步骤，那每个步骤具体做的事情如下：
1. Sencondary 初始化同步完成之后，开始增量复制，通过 produce 线程在 Primary oplog.rs 集合上建立 cursor，并且实时请求获取数据。
2. Primary 返回 oplog 数据给 Secondary。
3. Sencondary 读取到 Primary 发送过来的 oplog，将其写入到队列中。
4. Sencondary 的同步线程会通过 ```tryPopAndWaitForMore``` 方法一直消费队列，当每次达到一定的条件之后，就会将数据给 prefetchOps 方法处理，prefetchOps 方法主要将数据以 database 级别切分，便于后面多线程写入到数据库中。如果采用的 WiredTiger 引擎，那这里是以 Docment ID 进行切分。满足以下条件之一即可：
   * 总数据大于 100MB
   * 已经取到部分数据但没到 100MB，但是目前队列没数据了，这个时候会阻塞等待一秒，如果还没有数据则本次取数据完成。
5. 最终将划分好的数据以多线程的方式批量写入到数据库中（在从库批量写入数据的时候 MongoDB 会阻塞所有的读）。
6. 然后再将 Queue 中的 Oplog 数据写入到 Sencondary 中的 oplog.rs 集合中。

#### 心跳


#### 故障转移

如果主节点挂了，其中一个备份节点会自动选举为主节点。第一个检测到主节点挂了的备份节点会成为新的主节点。


## 参考文献

[【1】深入浅出 MongoDB 复制](https://www.infoq.cn/article/mongodb-replication)