---
layout: post
title: "存储 系列 数据复制"
subtitle: '复制：通过互联网络在多个(机器)实例上保存相同数据的副本。'
author: "lichao"
header-img: "img/post/bg/post-bg-2015.jpg"
catalog: true
tags:
  - store
---

复制/多副本的目的：
- 高可用性：即使某台机器（或多台机器、整个数据中心）出现故障，系统也能正常运行；
- 连接断开与容错：允许（存储）应用程序间 出现网络中断时继续工作；
- 低延迟：将数据放置在距离用户较近的地方，从而实现更快的交互；
- 可扩展性：采取多副本读取，大幅度提高系统操作的吞吐量。

本文将讨论以下复制方案：(单)主从复制、多主复制、无主复制。

## 主从复制
主从复制：写操作路由到某一个主节点(主副本)，从节点通过网络复制得到从副本。
- 主节点：支持读/写操作
- 从节点：仅支持读操作
**多副本节点不可避免会引入 数据一致性的问题，不同的复制实现都会做出数据一致和性能的权衡。**
![主从同步](/img/post/store/主从同步.png)
> 注：这里的主节点/从节点 可以认为是一种角色，单个实例可能有多种角色（参考Kafka的分区）
### 常见复制方案
#### 异步复制（Asynchronous Replication）
异步复制描述：
1. 客户端发送写请求；
2. 主节点写入本地存储后，直接响应客户端写成功；
  1. 主节点用另外一个线程，将 新数据 发送到从节点。
![异步复制](/img/post/store/异步复制.png)

**优势**：写性能好，延迟低；
**问题**：可能会发生数据丢失；
- 主节点尚未来得及将全部数据 复制到节点，然后挂了；从节点晋升为新主节点后，是没有全部数据的，此时对外服务相当于丢失了部分数据。

> 工程实现上（如Redis）通常可配置：当从节点落后主节点过多的时候，主节点会拒绝写入，以防止数据丢失过多的问题。如 共3个从节点，当有2个从节点复制落后均超过10秒，主节点则拒绝写入。

#### 全同步复制（Fully Synchronous Replication）
全同步：
1. 客户端发送写请求；
2. 主节点写入本地存储后，将 新数据 发送到所有从节点；
3. 当【所有从节点】都返回成功后，才响应客户端写成功；
![全同步复制](/img/post/store/全同步复制.png)

**优势**：数据保证完整，不会发生数据丢失（除非全部节点磁盘都损坏）；

**问题**：延迟取决于最慢的那个从节点；只要和其中一个节点网络连接有问题，延迟将拉得很高。
- 因为性能的问题，工程应用较少。

> 工程实现上，因为性能上的问题，往往只会作为一个可选项（如kafka生产者配置中的acks=all）

#### 半同步复制（Semisynchronous Replication）
半同步：
1. 客户端发送写请求；
2. 主节点写入本地存储后，将 新数据 发送到所有从节点；
3. 当有【一个从节点】返回成功后，就响应客户端写成功；
![半同步复制](/img/post/store/半同步复制.png)
**优势**：半同步属于异步和全同步的折中方案，保证数据完整的前提下尽量减少对性能的影响；

**问题**：写性能比不上异步复制，数据可靠性比不上全同步复制。

**工程实现上（如MySQL）**：
1. 从节点确认的数量通常是可以配置的，即可以配置 N 个从节点返回ok后，才响应客户端成功。
2. 考虑到节点间的网络抖动问题，可以采用 异步复制 作为兜底方案。
3. 从节点响应ok后，并非就意味着数据 在从节点 就立马可见了。
  1. MySQL的从就是使用Relay Log先接住，然后再在本地执行，最终才写入binlog（此时才可见）。

#### 写过半成功（Quorum）
过半成功，主要出现在 etcd、zookeeper 等基于共识算法（Raft/Zab等）的分布式存储组件中：
1. 客户端发送写请求；
2. 主节点写入本地存储后，将 新数据 发送到所有从节点；
3. 当有【过半节点】写成功后，就响应客户端写成功；
  1. 主节点最终的 Commit 到 从节点。
![写过半成功](/img/post/store/写过半成功.png)

因为要等待过半的节点响应写成功，性能 会介于 半同步 和 全同步之间。

> 比丢数据更可怕的是 有多个节点同时进行写入（即期望只有单个主节点的集群中出现多个主节点，即脑裂），过半成功是可以天然解决脑裂的问题的（只会有一个主节点写成功）；

#### 常见存储组件的复制方案
|      数据库     |    异步     |    半同步    |    过半成功    |    全同步     |
|      ---       |    ---      |     ---     |      ---     |     ---      |
|      Redis     |  支持（默认） |     -       |      -       |      -       |
|      MySQL     |  支持（默认） |    支持      |      -       |      -       |
|      ByteDoc   |  支持（默认） |    支持      |  支持(majority) |    -        |
|      Abase1.X  |  支持（默认）|支持 |  -  |  -  |
|      ByteKV    |   -  |  -  | 支持(raft协议)| -  |
|      ByteSQL(基于ByteKV) |  -  |  -  | 支持(raft协议) |- |
|      ByteTable |  -  |  -  | 支持(raft协议)|  -  |
|      ByteNDB   |  -  |  -  | 支持(类paxos协议)|  -  |
|      ByteGraph(基于Abase) | 支持（默认）| 支持 |  -  |  -  |
|      ByteGraph(基于ByteKV)|  -  |  -  | 支持(raft协议)|  -  |
|      RocketMQ | 支持（默认）| 支持| 开源版本4.5+ 支持(raft协议)|-|
|      BMQ |依赖于HDFS保证持久性，acks=all时写入HDFS后会flush|

其中全同步因为性能问题，工程实现上比较少；过半成功主要应用一些特殊的场景（如选主等）；最常见的选型是在 异步和半同步 之间，关于两者的性能差距参考：
- MySQL5.7：(增强)半同步相较于异步复制 损失约为10~20%左右；
- RocketMQ：[官方博客](http://140.205.61.252/2016/03/24/rmq-vs-kafka/)号称 (半) 同步复制相较于异步复制 性能损失约为20%~30%（2016-03）；

> 保证数据可靠性（持久性）的核心配置还有 **是否立即刷盘（同步刷盘）**；同复制一样，刷盘策略越严格，数据可靠性（持久性）越高，但相对的性能会越低。以MySQL 的 redo log 为例：
- 当事务进行提交时，会根据 ```innodb_flush_log_at_trx_commit``` 配置决定刷盘行为：
  - 0：不会主动触发写入磁盘的操作;（由后台线程进行每秒刷盘）；进程挂了会出现数据丢失；
  - 1：将log buffer写入log file，并且flush(刷盘)；断电也不会出现数据丢失；
  - 2：将log buffer写入log file，但是不进行flush(刷盘)；即只写到OS文件系统内存，真正刷盘动作交给OS；DB宕机不会出现数据丢失，但是断电会（OS直接挂了）


### 高可用实现方案
在分布式系统中，因为各种原因，网络连接出现问题、实例节点挂掉等问题往往是不可避免的。
- 从节点失效：不会影响到写的可用性，读时只要路由到其他节点即可。当节点恢复后，再通过指定复制偏移值，到主节点那边拉取数据，将进度赶回来即可。
- 主节点失效：对于很多存储来讲，主节点失效意味着 某些记录无法正常写入了，这时需要进行重新选一个新的主节点出来，客户端写请求路由到新主上，保证存储系统正常进行。

本节主要讨论主节点失效的情况。这里会涉及到两个点：
1. 故障检测：如何 判定 主节点 已经失效？
2. 故障转移：选择哪个 从节点 作为新的 主节点？由谁触发？客户端怎么知道变更？


**Redis：**      
[**HA组件-哨兵**]()

[**HA组件-集群**](https://bailing1992.github.io/2019/12/24/redis-%E7%B3%BB%E5%88%97-%E9%9B%86%E7%BE%A4/#%E9%9B%86%E7%BE%A4%E5%AE%B9%E9%94%99)

**MySQL：**      
[**HA组件-Orchestrator**]()


### 多主复制

### 无主复制