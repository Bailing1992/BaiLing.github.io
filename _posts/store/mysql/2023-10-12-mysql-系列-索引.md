---
layout: post
title: "MySQL 系列 索引"
subtitle: 'MySQL 技术内幕：InnoDB存储引擎'
author: "lichao"
update_at: "2023-10-10"
header-img: "img/post/bg/post-bg-夕阳.jpeg"
catalog: true
tags:
  - mysql
---

> 索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。索引的常见模型包括哈希表、有序数组和搜索树；

## 索引数据结构

### B+树

> B+Tree是为磁盘或其它辅助存储设备设计的一种平衡查找树（满足任意节点的两个子树的高度最大差为1）。

众所周知，MySQL默认存储引擎InnoDB采用的是B+Tree索引，其特点是：

- 高扇出性：每个树节点只存放键值，不存放数值，而由叶子节点存放数值。这样会使树节点的度比较大，而树的高度就比较低，从而有利于提高查询效率。
- 叶子节点存放数值，并按照值大小顺序排序，且带指向相邻节点的指针，以便高效地进行区间数据查询
- 并且所有叶子节点与根节点的距离相同(叶子结点在同一层)，因此任何查询的效率都很相似。
- B+Tree的数据更新操作不从根节点开始，而从叶子节点开始，并且在更新过程中树能以比较小的代价实现自平衡。

B+Tree索引并不能找到一个给定键值的具体行。B+Tree索引能找到的只是被查找数据行所在的页。然后数据库通过把页读入到内存，再在内存中进行查找，最后得到要查找的数据。在页中的查找可以理解为二分查找。

> - 插入：采用旋转操作使B+Tree减少页的拆分操作；
> - 删除：使用填充因子来控制树的删除变化；

#### 查询性能

InnoDB存储引擎中页的大小为16KB，一般表的主键类型为int（占用4个字节）或long（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值（因为是估值，为方便计算，这里的K取值为10^3）。也就是说一个深度为3的B+Tree索引可以维护```10^3*10^3*10^3 = 10```亿条记录。

在数据库中，B+Tree的高度一般都在2~4层。MysSQL的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。再考虑到非叶子节点基本都会缓存在数据库的Buffer_Pool中，实际的IO次数要更少一些，因此业务无需担心因为数据量的增大导致B+Tree索引的性能有严重的劣化。

正是由于B+Tree的上述优点，它成了传统关系型数据库的宠儿。当然，它也并非无懈可击，它的主要缺点在于随着数据插入的不断发生，叶子节点会慢慢分裂——这可能会导致逻辑上原本连续的数据实际上存放在不同的物理磁盘块位置上，在做范围查询的时候会导致较高的磁盘 IO，以致严重影响到性能。

### LSM 树

对于写入量比较大的服务，出于性能和存储成本考虑，DBA会建议用户使用RocksDB，而RocksDB使用的是LSM-Tree（log structed merge tree）。

## 索引类型

首先从索引存放的内容上分为聚簇索引（主键）和非聚簇索引（二级索引）。无论是InnoDB还是RocksDB，都是索引组织表，即每个表有且只有一个聚簇索引，存放主键和records。但可以有多个二级索引，存放二级索引值和主键的值。

![索引示例](/img/post/mysql/索引示例.png)

如上图所示，我们可以直接通过聚簇索引找到全部的records，但是通过二级索引需要先找到对应的主键，再拿着获得的主键到聚簇索引查找records，这个过程称为回表。这里要注意的一点是，虽然B+Tree的特点决定了二级索引肯定是连续的，但是回表到聚簇索引上就可能是离散的了。因此有时候用户会比较困扰，为什么只通过二级索引扫描了1000行，但是会产生MB级别的IO，因为最坏的情况可能是这1000行分布在1000个主键的page上面。

由于MySQL是索引组织表，因此即使用户剪标没有指明primary key，DB也会分配一个隐藏的row_id列作为主键。不过，在这里DBA一般建议用户还是在创建表的时候显示指明一个有自增属性的ID作为主键。

### 聚簇索引（又称主键索引）

聚簇索引就是按照每张表的主键构造一颗B+树，叶子节点中存放整张表的行记录数据，叶子节点即为数据页，每个数据页通过双向链表进行链接。

> 聚簇索引的存储并不是物理上连续的，而是逻辑上连续的:
>
> - 页通过双向链表链接，页按照主键的顺序排序;
> - 每个页中的记录也是通过双向链表进行维护，物理存储同样可以不按照主键存储;
> - 在多数情况下，查询优化器倾向于采用聚簇索引。因为聚簇索引能够在B+树索引的叶子结点上直接找到数据，有利于对于主键的排序查找和范围查找。查询优化器能够快速发现某一段范围的数据页需要扫描。

### 二级索引（又称辅助索引、非聚簇索引）

叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含一个书签（相应行数据的聚集索引键，即主键值）。该书签用来告诉InnoDB存储引擎哪里可以找到与索引相对应的行数据。二级索引的书签就是相应行数据的聚簇索引键（页级别）。

当通过二级索引来寻找数据时，InnoDB 存储引擎会遍历二级索引并通过页级别的指针获取指向主键索引的主键。然后再通过主键索引来找到完整的行记录。

### 唯一索引

> 顾名思义唯一索引不允许两行具有相同的索引值。因此主键也是一种特殊的唯一索引。

对于查找，唯一索引和普通索引的区别：

- 对于普通索引来说，查找到满足条件的第一个记录后，需要查找下一个记录，直到碰到第一个不满足条件的记录。
- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。
  
对于更新，唯一索引和普通索引的区别：

- 唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用
- 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反**唯一性约束**。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 **change buffer** 了。

### 联合索引

联合索引是指对表上的多个列进行索引，符合向左匹配原则。联合索引的键值的数量不是1，而是大于等于2。键值都是排序的，通过叶子节点可以逻辑上顺序地读出所有数据。

**要点：联合索引已经对每个键值进行了排序处理（可与 order by结合使用）；**

```sql
create table buy_log(
   user_id int unsigned not null,
   buy_date date
   primary key (user_id),
   key idx_a_b(user_id, buy_date)
)
```

1. 每个叶子节点包含的键值个数: `select * from buy_log where user_id =2;` 优化器优先选择单个索引，因为该索引的叶子节点包含单个键值，所以理论上一个页存放的记录应该更多。
2. 能否利用多个键值的联合索引: 联合索引的每个字段都是有序的，`order by` 能够利用这些有序的数据，但需要满足向左匹配原则：
`select * from buy_log where user_id = 1 order by buy_date desc limit 3;` 优化器使用了联合索引，因为第二个字段 `buy_date` 是有序的。

> 优化项：因为每次修改需要修改全部索引的B+Tree，所以索引创建多了会导致写入性能的下降，索引肯定不是越多越好。在创建索引的时候我们需要尽量创建多个索引列的联合索引。

### 覆盖索引

覆盖索引（covering index）指一个查询语句的数据只用从二级索引中就能够取得，不必从数据表（查询聚簇索引）中读取（不用回表）。也可以称之为实现了索引覆盖。

1. 覆盖索引的一个好处是二级索引不包含整行记录的所有信息，故其大小要远小于聚簇索引，因此可以减少大量的IO操作；
2. 统计查询时，选择二级索引可以减少IO操作；

```sql
create table buy_log(
    user_id int unsigned not null,
    buy_date date
    primary key (user_id),
    key idx_a_b(user_id, buy_date)
)
```

1. `select count(*) from buy_log`: 优化器查询二级索引进行统计，原因是二级索引比聚簇索引更小，每个叶子节点包含的数据条数更多。
2. `select count(*) from buy_log where buy_date>= '2011-01-01' and buy_date < '2011-02-01'`: 统计查询，可以利用到覆盖索引中的信息，因此优化器会使用该联合索引。

> 使用前缀索引就用不上覆盖索引对查询性能的优化了。

### hash 索引

hash索引在InnoDB引擎中叫作自适应哈希索引，它是由数据库自身根据数据的使用情况创建的，并不能人为的干预，所以叫作自适应哈希索引，采用的是哈希表数据结构，所以对于字典类型查询就非常的快，但是对于范围查询就无能为力了。DB可以通过≈innodb_adaptive_hash_index`参数动态的开关hash索引。

### Full-Text 索引

在B+Tree索引中，当执行`select * from blog where content like %xxxx%`语句时，索引会失效。全文索引可以有效的解决这种语句查询。全文索引是一种比较特殊的索引，一般都是基于倒排索引来实现的，es 也是使用倒排索引。倒排索引跟B+Tree索引一样也是一种数据结构，在辅助表中存储了单词与单词自身在一个或多个文档中所在位置的映射。现在有很多专门做全文索引的软件，例如solr、elasticsearch等，MySQL中的全文索引实现原理跟这些差不多。

### 前缀索引

对于字符串字段，可以添加前缀索引，使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。

```sql
select count(distinct left(email, 4)）as L4 from SUser;
```

## 最佳实践

创建一个合理有效的索引是每个MySQL用户必备的技能，在创建的时候，用户需要注意以下原则：

- 避免不必要/冗余的索引：索引需要额外的空间，此外还会拖慢写入的速度，因此只为查询常用的列创建索引，并且尽量避免一个列上创建多个索引；
- 选择索引列：索引列离散性越高选择性就越好，索引列类型尽量小；
- 最左匹配原则： 如果查询的时候查询条件精确匹配索引的左边连续一列或几列，则此列就可以被用到；
- 联合索引：
  - 经常用的列优先 【最左匹配原则】
  - 选择性（离散度）高的列优先【离散度高原则】
  - 宽度小的列优先【最少空间原则】
- 覆盖索引：覆盖索引可减少数据库IO，将随机IO变为顺序IO，可提高查询性能。

### 无法使用索引的场景

如果没能很好的遵守以上原则，则会导致MySQL无法使用索引，从而导致扫描全表，DB过载，甚至系统崩溃等严重问题，常见的错误场景有以下几类：

```sql
CREATE TABLE person_info(
    id INT NOT NULL auto_increment,
    name VARCHAR(100) NOT NULL,
    birthday DATE NOT NULL,
    phone_number CHAR(11) NOT NULL,
    country varchar(100) NOT NULL,
    PRIMARY KEY (id),
    KEY idx_name_birthday_phone_number (name, birthday, phone_number) 
);
```

- 不按照顺序查询: `SELECT * FROM person_info WHERE birthday = '1990-09-27';`
- ASC和DESC混用: `SELECT * FROM person_info ORDER BY name, birthday DESC LIMIT 10;`
- 非前缀匹配: `SELECT * FROM person_info WHERE name LIKE '%As%';`
- 排序列不包括索引列: `SELECT * FROM person_info ORDER BY name, country LIMIT 10;`
- 索引列上有计算: `SELECT * FROM person_info WHERE DATEDIFF(birthday,'1990-09-27')=0；`
- 范围查询之后的列: `SELECT * FROM person_info WHERE name = 'Tony' and birthday < '1990-09-27' and pyhone_number='110';`

## MySQL 内核相关优化

为了加快查询速度，针对一些特殊的场景，MySQL 分别做了相关的优化；

### MySQL Join的原理与实践

MySQL只支持一种join算法：Nested-Loop Join（嵌套循环连接），但Nested-Loop Join有三种变种；

#### Simple Nested-Loop Join

简单来说嵌套循环连接算法就是一个双层for循环 ，通过循环外层表的行数据，逐个与内层表的所有行数据进行比较来获取结果，当执行`select * from user tb1 left join level tb2 on tb1.id=tb2.user_id`时，整个匹配过程会如下图：
![索引示例](/img/post/mysql/ad44518a-a4d0-4528-8b6b-dc1998c7f0b4.png)
Simple Nested-Loop Join 简单粗暴容易理解，就是通过双层循环比较数据来获得结果，但是这种算法显然太过于粗鲁，如果每个表有1万条数据，那么对数据比较的次数=1万 * 1万 =1亿次，很显然这种查询效率会非常慢。当然MySQL肯定不会这么粗暴的去进行表的连接，所以就出现了后面的两种对Nested-Loop Join优化算法，在执行join查询时MySQL会根据情况选择后面的两种优join优化算法的一种进行join查询。

#### Index Nested-Loop Join（索引嵌套循环连接）

Index Nested-Loop Join的优化思路主要是为了减少内层表数据的匹配次数， 简单来说Index Nested-Loop Join 就是通过外层表匹配条件 直接与内层表索引进行匹配，避免和内层表的每条记录去进行比较， 这样极大的减少了对内层表的匹配次数，从原来的`匹配次数=外层表行数*内层表行数`，变成了`外层表的行数*内层表索引的高度`，极大的提升了join的性能。

例如查询 `select * from user tb1 left join level tb2 on tb1.id=tb2.user_id`时, 当level表的user_id为索引的时候执行过程会如下图：
![索引示例](/img/post/mysql/66ea85ca-e809-4a44-95e9-dfc54d202ecb.png)
注意和Simple Nested-Loop Join的区别就是user_id属于user_level的索引列，因此无需遍历user_level即可找到与外表user_info的id相同的record。

#### Block Nested-Loop Join（缓存块嵌套循环连接）

Block Nested-Loop Join 其优化思路是减少内层表的扫表次数，通过简单的嵌套循环查询的图，我们可以看到，左表的每一条记录都会对右表进行一次扫表，扫表的过程其实也就是从内存读取数据的过程，那么这个过程其实是比较消耗性能的。
![索引示例](/img/post/mysql/dabefaf7-9811-4a74-8b77-feaf5675ff3e.png)

所以缓存块嵌套循环连接算法意在通过一次性缓存外层表的多条数据，以此来减少内层表的扫表次数，从而达到提升性能的目的。如果无法使用Index Nested-Loop Join的时候，数据库是默认使用的是Block Nested-Loop Join算法的。

当level 表的 user_id 不为索引的时候，默认会使用Block Nested-Loop Join算法，匹配的过程类似下图。
![索引示例](/img/post/mysql/c6eda4a5-32e0-462d-b584-8e2512a1dd86.png)

1. 使用Block Nested-Loop Join算法需要开启优化器管理配置的optimizer_switch的设置`block_nested_loop`为on默认为开启，如果关闭则使用Simple Nested-Loop Join算法；
2. 设置join buffer的大小，通过join_buffer_size参数可设置join buffer的大小；

#### 小结

不论是Index Nested-Loop Join还是Block Nested-Loop Join都是在Simple Nested-Loop Join的算法的基础上进行优化，这里Index Nested-Loop Join和Nested-Loop Join算法是分别对Join过程中循环匹配次数和IO次数两个角度进行优化。

Index Nested-Loop Join是通过索引的机制减少内层表的循环匹配次数达到优化效果，而Block Nested-Loop Join是通过一次缓存多条数据批量匹配的方式来减少外层表的IO次数，同时也减少了内层表的扫表次数，通过理解join的算法原理我们可以得出以下表连接查询的优化思路。

1. 永远用小结果集驱动大结果集(其本质就是减少外层循环的数据数量)
2. 为匹配的条件增加索引(减少内层表的循环匹配次数)
3. 增大join buffer size的大小（一次缓存的数据越多，那么内层包的扫表次数就越少）
4. 减少不必要的字段查询（字段越少，join buffer 所缓存的数据就越多）

### 索引条件下推（Index Condition Pushdown）

#### 优化背景

什么是回表? 查询二级索引获得主键后根据主键值从聚集索引中获取到完整记录到过程叫做回表。

```sql
CREATE TABLE person_info(
        id INT NOT NULL auto_increment,
        name VARCHAR(100) NOT NULL,
        birthday DATE NOT NULL,
        phone_number CHAR(11) NOT NULL,
        country varchar(100) NOT NULL,
        PRIMARY KEY (id),
        KEY idx_name_birthday_phone_number (name, birthday, phone_number)                                                 
);
```

查询语句是:

```sql
SELECT * FROM person_info WHERE name > 'Asa' AND name < 'Barlow'; 
```

这个时候会使用二级索引进行查询，具体到查询步骤可以分为以下几个步骤：

1. 从二级索引`idx_name_birthday_phone_number`中获取到满足条件`（name > 'Asa' AND name < 'Barlow'）`的记录。
2. 由于需要返回所有的列但是二级索引中只包含几列`（name, birthday, phone_number）`，需要根据从二级索引中获取到的主键去聚集索引中获取完整的记录返回给用户，这个过程就叫做回表。

由于二级索引中的值会根据列值进行排序，所以第一步从二级索引中获取数据时，获取的数据在磁盘上的存储是连续的，分布在一个或者相邻的几个数据页中，这样对于磁盘的读取是顺序io。

而在第二个步骤中由于从第一个步骤中获取到的每一条记录的主键值大概率都不相同，而聚集索引是按照主键排序的，这个时候访问聚集索引中的每一条记录都大概率分布在不同的数据页中，对于磁盘的读取就大概率是随机io。

相信大家都知道对于磁盘而言，随机io通常都比顺序io慢很多。总结一下，发生回表的时候首先使用两个索引，一个二级索引，一个聚集索引。同时二级索引上的磁盘io是顺序io，聚集索引上的磁盘io是随机io。这样就会出现一个现象就是需要回表的记录越多，使用二级索引的效率就越低。

#### 优化思路

MySQL 5.6引入的索引下推优化（index condition pushdown)。在满足最左匹配的基础上，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

Index Condition Pushdown是一种根据索引进行查询的优化方式。在支持Index Condition Pushdown之后，MySQL数据库会在取出索引的同时，判断是否可以进行`where`条件的过滤，也就是将 where 的部分过滤操作放在了存储引擎层。

```sql
SELECT * FROM s1 WHERE name > 'Asa' AND name LIKE '%b';
```

- 如果没有使用index condition pushdown这个优化的时候。查询步骤是这样的:
  1. 先根据过滤条件`name > 'Asa'`将符合条件的记录从二级索引中找出来。
  2. 根据从二级索引中获取到记录的主键值回表从聚集索引中获取到完整的数据。再检测记录是不是满足这个`name LIKE '%b'`过滤条件，符合的记录返回给用户。
可以看到上述过程中`name > 'Asa'`可以使用到索引，`name LIKE '%b'`却不能使用到索引。

- 使用index condition pushdown优化的时候，查询步骤是这样的：
  1. 先根据过滤条件`name > 'Asa'`将符合条件的记录从二级索引中找出来。
  2. 获取到二级索引的记录后先不回表，先检测一下是不是满足`name LIKE '%b'`这个过滤条件，符合条件的再进行回表。
之前我们提到了回表操作是一个耗时的过程，使用了index condition pushdown这个优化后可以减少回表的记录，从而加快了查询速度。

### Fast Index Creation 快速索引创建

对于辅助索引的创建，InnoDB存储引擎会对创建索引的表加一个S锁。在创建的过程中，不需要重建表，因此速度较之前提高很多，并且数据库的可用性也得到了提高。
由于加了S锁，在创建过程中只能对该表进行读操作。
*对于主键的创建和删除需要重建一张表。*

### Multi-Range Read 多范围读

Multi-Range Read 优化的目的是减少磁盘的随机访问，并且将随机访问转化为较为顺序的数据访问。
MySQL 将根据辅助索引获取的结果集根据主键进行排序，将随机访问化为较为顺序的数据访问，可以按照主键顺序书签查找（回表）
按照主键顺序进行访问，可以避免频繁的离散读操作导致的缓存中页被替换出缓存池，然后又不断写入缓存池的现象。
MRR还可以将某些范围查询，将查询条件进行拆分，拆分为键值对（在拆分的过程中，直接过滤一些不符合查询条件的数据），以此来进行批量的数据查询。

### Index Merge

一般情况下我们只能利用单个二级索引进行查询。接下来我们提到的index merge就是一种特殊的情况，在这种特殊情况下可以使用多个二级索引查询。

Index merge主要分为以下三类：

- intersection merge（交集合并）

#### intersection merge（交集合并）

一个查询可以使用多个二级索引查询，返回给用户的结果取多个二级索引查询的结果的交集。

```sql
CREATE TABLE single_table (
        id INT NOT NULL AUTO_INCREMENT,
        key1 VARCHAR(100),
        key2 INT,
        key3 VARCHAR(100),
        key_part1 VARCHAR(100),
        key_part2 VARCHAR(100),
        key_part3 VARCHAR(100),
        common_field VARCHAR(100),
        PRIMARY KEY (id),
        KEY idx_key1 (key1),
        UNIQUE KEY idx_key2 (key2),
        KEY idx_key3 (key3),
        KEY idx_key_part(key_part1, key_part2, key_part3)                                          
) Engine=InnoDB CHARSET=utf8;

# 查询sql是：
SELECT * FROM single_table WHERE key1 = 'a' AND key3 = 'b'; 
```

- 不使用intersection merge优化时候的查询步骤：
  1. 从idx_key1二级索引中获取满足过滤条件的记录。
  2. 根据idx_key1二级索引获取到的主键值回表，获取到完整的记录数据后判断key3 = 'b'过滤条件是否满足。
  
  或者

  1. 从idx_key3二级索引中获取满足过滤条件的记录。
  2. 根据idx_key3二级索引获取到的主键值回表，获取到完整的记录数据后判断key1 = 'a'过滤条件是否满足。

- 使用intersection merge优化时候的查询步骤：
  1. 首先从idx_key1二级索引中获取到满足过滤条件的记录
  2. 再从idx_key3二级索引中获取满足过滤条件的记录
  3. 计算出这两个二级索引记录的主键交集，根据交集中的主键值回表将完整记录从聚集索引中读取出来返回给用户。

- 使用intersection merge的条件：
  - 二级索引是等值匹配，对于联合索引需要联合索引的每个列都等值匹配;

  ```sql
  # 可以使用 intersection merge                                        
  SELECT * FROM single_table WHERE key1 = 'a' AND key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c'; 
  # 不可以使用intersection merge
  SELECT * FROM single_table WHERE key1 > 'a' AND key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c'; 
  # 不可以使用intersection merge
  SELECT * FROM single_table WHERE key1 = 'a' AND key_part1 = 'a'; 
  ```

  - 主键列可以是范围匹配;

  ```sql
  #可以使用intersection merge
  SELECT * FROM single_table WHERE id > 100 AND key1 = 'a';
  ```

对于 InnoDB 的二级索引来说，记录先是按照索引列进行排序，如果该二级索引是一个联合索引，那么会按照联合索引中的各个列依次排序。而二级索引的用户记录是由 索引列 + 主键 构成的，二级索引列的值相同的记录可能会有好多条，这些索引列的值相同的记录又是按照主键的值进行排序的。所以之所以在二级索引列都是等值匹配的情况下才可能使用 Intersection索引合并，是因为只有在这种情况下根据二级索引查询出的结果集是按照主键值排序的。这样的好处是因为排序后求交集的效率高。

另外，不仅是多个二级索引之间可以采用 Intersection 索引合并，可以有聚簇索引参加，也就是我们上边写的情况二 :在搜索条件中有主键的范围匹配的情况下也可以使用 Intersection 索引合并索引合并。

假设这个查询可以采用 Intersection 索引合并，我们理所当然的以为这个查询会分别按照 id > 100 这个条件从聚簇索引中获取一些记录，在通过 key1 = 'a' 这个条件从 idx_key1 二级索引中获取一些记录，然后再求交集， 其实这样就把问题复杂化了，没必要从聚簇索引中获取一次记录。别忘了二级索引的记录中都带有主键值的，所以可以在从 idx_key1 中获取到的主键值上直接运用条件 id > 100 过滤就行了，这样多简单。所以涉及主键的搜索条件只不过是为了从别的二级索引得到的结果集中过滤记录罢了，是不是等值匹配不重要。

#### union merge（并集合并）

一个查询可以使用多个二级索引查询，返回给用户的结果取多个二级索引查询的结果的并集。

交集合并更适合不同索引的过滤条件之间使用and连接的情况。那并集合并就更适合不同过滤条件之间是使用or连接的情况，例如：

```sql
SELECT * FROM single_table WHERE key1 = 'a' OR key3 = 'b' 
```

使用union merge的条件：

1. 二级索引是等值匹配，对于联合索引需要联合索引的每个列都等值匹配
2. 主键列可以是范围匹配
3. 使用intersection meger的过滤条件

```sql
SELECT * FROM single_table WHERE key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c' OR (key1 = 'a' AND key3 = 'b');
```

优化器可能采用这样的方式来执行这个查询:

1. 先按照搜索条件`key1 = 'a' AND key3 = 'b'`从索引`idx_key1`和`idx_key3`中使用 Intersection 索引合并的方式得到一个主键集合。
2. 再按照搜索条件`key_part1 = 'a' AND key_part2 = 'b' AND key_part3 = 'c'`从联合索引`idx_key_part`中得到另一个主键集合。采用 Union 索引合并的方式把上述两个主键集合取并集，然后进行回表操作，将结果返回给用户。

#### sort-union merge （排序并集合并）

一个查询可以使用多个二级索引查询，先将多个二级索引查询结果按照主键值排序， 之后返多个二级索引查询的结果的并集返回给用户。

由于union merge的使用条件太苛刻，必须保证每个二级索引都是等值匹配才能使用，而下面这个例子中的查询就无法使用union merge：
SELECT * FROM single_table WHERE key1 < 'a' OR key3 > 'z';
无法使用的原因是因为从每个二级索引获取到记录的主键值不是排序的。因此出现了sort-union merge这种优化，具体执行的步骤：

1. 首先根据过滤条件从idx_key1二级索引中获取记录并且根据主键值排序
2. 然后根据过滤条件从idx_key3二级索引中获取记录并且根据主键值排序
3. 最后将两个结果集取并集后回表。

## 相关问题

### 添加索引时需要考虑的因素?

1. 不是在所有的查询条件中出现的列都需要添加索引。在表中数据具有高选择性时，B+树索引才有意义（高选择性，使用```show index```命令结果中的 ```cardinality``` 列，表示索引中不重复记录数量的预估值）；
2. 关注多张表之间的联接操作，关联的键需要加索引
3. 在 OLAP 应用中，通常需要对时间字段进行索引，因为大多数统计需要根据时间维度进行数据的筛选。

> 注：Cardinality 的统计放在存储引擎层进行，通过采样的方式进行

### 自增索引有什么好处？

1. 自增主键的插入数据模式，正符合递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。
2. 主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。由于每个非主键索引的叶子节点上都包含主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。

### 优化器什么时候不使用索引?

- 有时优化器没有选择扫描辅助索引，而是通过扫描聚集索引，这种情况多发生于范围查找、Join链接操作等情况下：
  - 当查询数据是整行信息而辅助索引不能覆盖时（需要回表查询），而且被查询数据量很多时（大于20%），选择聚集索引。
  - 对于不能进行索引覆盖的情况，优化器选择辅助索引的情况是，通过辅助索引查询的数据量是少量的。
- 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能，但是可以选择全索引扫描。
  - 有数据类型转换，就需要走全索引扫描。在MySQL中，字符串和数字做比较的话，是将字符串转换成数字
  - 有隐式字符编码转换，就需要走全索引扫描

### 如何选择索引

优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。

一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，称之为“基数”（cardinality）。
![索引基数](/img/post/mysql/索引基数.png)

从性能的角度考虑，InnoDB使用采样统计，默认会选择`N`个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。因此，上述两个索引显示的基数并不相同。而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 `1/M` 的时候(innodb_stats_persistent=on时默认10，反之16)，会自动触发重新做一次索引统计。

![索引基数](/img/post/mysql/索引统计.png)

### 使用索引查询一定能提高查询的性能吗？

通常，通过索引查询数据比全表扫描要快，也必须注意到它的代价。

1. 索引需要空间来存储，也需要定期维护，每当有记录在表中增减或索引列被修改时，索引本身也会被修改。这意味着每条记录的INSERT，DELETE，UPDATE 将为此多付出 4、5 次的磁盘 I/O。 因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况:
2. 基于一个范围的检索，一般查询返回结果集小于表中记录数的 30%
3. 基于非唯一性索引的检索

### 为什么MySQL有时候会选择错索引？

相信很多用户都会有这个困扰，明明选择某个索引扫描的行数更少，为什么有时候DB还是选择了其他的索引甚至扫描了全表？原因有以下几点：

- 表增删十分频繁，导致扫描行数不准确：

由于MySQL对于删除的数据只是标记删除，后台再通过purge线程扫描标记删除的记录去做真正的空间回收，回收下来的页面会在下次需要新分配页面时候优先使用。这些特点导致频繁大量增删的时候，预估的统计信息不准确，可能会选择错误的索引。解决该类问题的方法是强制触发统计信息的更新，即analyze table。这个操作只是触发重新采样更新统计信息，因此用户不用担心这个操作会影响DML操作。

- 扫描的行数太多，优化器可能会走主键扫全表：

假设主键索引扫描行数是10W行，而普通索引需要扫描5W行，这种情况就会遇到优化器选择了扫描行数更多的主键索引。因为考虑到只有扫描主键才能拿到真正的records，不需要回表。而普通索引是需要先拿到主键值，再根据主键值获取对应的数据，这个过程优化器选择索引时需要计算的一个成本。因此这时候优化器是有可能会选择扫描主键而不是我们认为更加合适的某个二级索引的。

### 如何避免MySQL选错索引？

- Force Index

在MySQL中提供了`force index`来强制优化器使用这个索引。使用方法：`select * from table_name force index (idx_a) where a = 100;` 当优化器没有正确选择索引时是可以使用这种方案来解决。

- 去掉作用重复的索引

删掉误选的索引，简单粗暴，很多索引建立其实也是给优化器的一个误导，直接删掉即可。

- 改写SQL

修改SQL语句，主动引导MySQL使用期望的索引，一般情况这种做法比较考验用户对于系统的了解程度，建议先在类生产环境上验证后在正式修改上线。

```sql
-- 创建表
mysql> CREATE TABLE `t` (
    `id` int(11) NOT NULL,
    `a` int(11) DEFAULT NULL,
    `b` int(11) DEFAULT NULL,
    PRIMARY KEY (`id`),
    KEY `a` (`a`),
    KEY `b` (`b`)
) ENGINE=InnoDB;

-- 定义测试数据存储过程
mysql> delimiter ;
CREATE PROCEDURE idata ()
BEGIN

DECLARE i INT ;
SET i = 1 ;
WHILE (i <= 100000) DO
 INSERT INTO t
VALUES
 (i, i, i) ;
SET i = i + 1 ;
END
WHILE ;
END;
delimiter ;

-- 执行存储过程，插入测试数据
mysql> CALL idata ();
```

当执行以下查询的时候，就会发现MySQL并没有选择过滤性更好的a，而是选择了需要扫描更多行的b。这是因为由于需要进行字段b排序，虽然索引b需要扫描更多的行数，但本身是有序的，综合扫描行数和排序，优化器选择了索引b，认为代价更小。

```sql
mysql> explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;
+----+-------------+-------+-------+---------------+-----+---------+------+-------+------------------------------------+
| id | select_type | table | type  | possible_keys | key | key_len | ref  | rows  | Extra                              |
+----+-------------+-------+-------+---------------+-----+---------+------+-------+------------------------------------+
|  1 | SIMPLE      | t     | range | a,b           | b   | 5       | NULL | 50128 | Using index condition; Using where |
+----+-------------+-------+-------+---------------+-----+---------+------+-------+------------------------------------+
```

修改方案1：通过force index强制走索引a，纠正优化器错误的选择。这个方法最为简单有效但是过于死板，并不通用，且索引名称更变语句也需要变。

```sql
mysql> explain select * from t force index(a) where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;
+----+-------------+-------+-------+---------------+-----+---------+------+------+----------------------------------------------------+
| id | select_type | table | type  | possible_keys | key | key_len | ref  | rows | Extra                                              |
+----+-------------+-------+-------+---------------+-----+---------+------+------+----------------------------------------------------+
|  1 | SIMPLE      | t     | range | a             | a   | 5       | NULL |  999 | Using index condition; Using where; Using filesort |
+----+-------------+-------+-------+---------------+-----+---------+------+------+----------------------------------------------------+
```

修改方案2：调整索引，对表的每一列都创建索引无疑是一种很蠢的行为，不但会导致写入性能下降，数据成本增加，还会误导优化器。对于这种场景，一个合理的联合索引无疑是更好的选择。

```sql
ALTER TABLE `t` DROP INDEX `a`, DROP INDEX `b`, ADD INDEX `ab` (`a`,`b`) ;
```

修改方案3：引导 MySQL 使用我们期望的索引，按b,a排序，优化器需要考虑a排序的代价。

```sql
mysql> explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b,a limit 1;
+----+-------------+-------+-------+---------------+-----+---------+------+------+----------------------------------------------------+
| id | select_type | table | type  | possible_keys | key | key_len | ref  | rows | Extra                                              |
+----+-------------+-------+-------+---------------+-----+---------+------+------+----------------------------------------------------+
|  1 | SIMPLE      | t     | range | a,b           | a   | 5       | NULL |  999 | Using index condition; Using where; Using filesort |
+----+-------------+-------+-------+---------------+-----+---------+------+------+----------------------------------------------------+
```
