---
layout: post
title: "MySQL 系列 事务两阶段提交"
subtitle: 'MySQL 技术内幕：InnoDB存储引擎'
author: "lichao"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
  - MySQL
---

> 日志是 MySQL 数据库的重要组成部分。日志文件中记录着 MySQL 数据库运行期间发生的变化，也就是说用来记录 MySQL 数据库的客户端连接状况、SQL 语句的执行情况和错误信息等。当数据库遭到意外的损坏时，可以通过日志查看文件出错的原因，并且可以通过日志文件进行数据恢复。

MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。 redo log 是 InnoDB 引擎特有的日志，用来保证事务安全的。而 Server 层也有自己的日志，称为 binlog（归档日志），主要用来做主从复制和即时点恢复时使用的。

在 MySQL 中，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。MySQL 使用 WAL 技术来提升更新效率，WAL 的全称是 ```Write-Ahead Logging```，它的关键点就是先写日志，再写磁盘。具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到```redo log```里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。

因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。

> crash-safe 指 MySQL 服务器宕机重启后，能够保证：
>* 所有已经提交的事务的数据仍然存在。
>* 所有没有提交的事务的数据自动回滚。

这两种日志有以下三点不同: 
* redo log 是 InnoDB 引擎特有的。binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
* redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如 “给 ID = 2 这一行的 c 字段加 1”。
* redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

> 在主从复制结构中，要保证事务的持久性和一致性，需要对日志相关变量设置为如下：
* 如果启用了二进制日志，则设置 ```sync_binlog = 1```，即每提交一次事务同步写到磁盘中。
* 总是设置 ```innodb_flush_log_at_trx_commit = 1```，即每提交一次事务都写到磁盘中。


[详情请看-binlog](https://bailing1992.github.io/2020/05/25/mysql-%E7%B3%BB%E5%88%97-bin-log/)

[详情请看-redo log](https://bailing1992.github.io/2020/05/25/mysql-%E7%B3%BB%E5%88%97-redo-log/)

## 两阶段提交
MySQL 没有开启 binlog 的情况下，通过 redo log 将所有已经在存储引擎内部提交的事务应用 redo log 恢复，所有已经 prepare 但是没有 commit 的 transactions 将会应用 undo log 做 rollback。然后客户端连接时就能看到已经提交的数据存在数据库内，未提交被回滚地数据需要重新执行。

MySQL 开启 binlog 的情况下，MySQL 为了保证 master 和 slave 的数据一致性，就必须保证 binlog 和redo log 的一致性。 为此，MySQL 引入二阶段提交（two phase commit or 2pc），MySQL 内部会自动将普通事务当做一个 XA 事务（内部分布式事物）来处理：
* 自动为每个事务分配一个唯一的 ID（XID）。
* COMMIT 会被自动的分成 Prepare 和 Commit 两个阶段。
* Binlog 会被当做事务协调者(Transaction Coordinator)，Binlog Event 会被当做协调者日志。

![两阶段提交](/img/mysql/两阶段提交.png)   

以上的图片中可以看到，事务的提交主要分为两个主要步骤：
1. 准备阶段（Storage Engine（InnoDB）Transaction Prepare Phase）: 此时 SQL 已经成功执行，并生成 xid 信息及 redo 和 undo 的内存日志。然后调用 prepare 方法完成第一阶段，papare 方法实际上什么也没做，将事务状态设为 ```TRX_PREPARED```，并将 redo log 刷磁盘。
2. 提交阶段(Storage Engine（InnoDB）Commit Phase)
    1. 记录协调者日志，即 binlog 日志: 如果事务涉及的所有存储引擎的 prepare 都执行成功，则调用```TC_LOG_BINLOG::log_xid``` 方法将 SQL 语句写到 binlog（write() 将 binlog 内存日志数据写入文件系统缓存，fsync() 将 binlog 文件系统缓存日志数据永久写入磁盘）。此时，事务已经铁定要提交了。否则，调用 ```ha_rollback_trans``` 方法回滚事务，而 SQL 语句实际上也不会写到 binlog。
    2. 告诉引擎做 commit: 最后，调用引擎的commit完成事务的提交。会清除undo信息，刷redo日志，将事务设为TRX_NOT_STARTED状态。
3. 调用引擎的 commit 完成事务的提交。会清除 undo 信息，刷 redo 日志，将事务设为```TRX_NOT_STARTED```状态。

**由上面的二阶段提交流程可以看出，一旦步骤2中的操作完成，就确保了事务的提交，即使在执行步骤3时数据库发送了宕机。此外需要注意的是，每个步骤都需要进行一次fsync操作才能保证上下两层数据的一致性。步骤2的fsync参数由sync_binlog=1控制，步骤3的fsync由参数innodb_flush_log_at_trx_commit=1控制，俗称“双1”，是保证CrashSafe的根本。**

**事务的两阶段提交协议保证了无论在任何情况下，事务要么同时存在于存储引擎和 binlog 中，要么两个里面都不存在，这就保证了主库与从库之间数据的一致性。如果数据库系统发生崩溃，当数据库系统重新启动时会进行崩溃恢复操作，存储引擎中处于 prepare 状态的事务会去查询该事务是否也同时存在于 binlog 中，如果存在就在存储引擎内部提交该事务（因为此时从库可能已经获取了对应的 binlog 内容），如果 binlog 中没有该事务，就回滚该事务。例如：当崩溃发生在第一步和第二步之间时，明显处于 prepare 状态的事务还没来得及写入到 binlog 中，所以该事务会在存储引擎内部进行回滚，这样该事务在存储引擎和 binlog 中都不会存在；当崩溃发生在第二步和第三步之间时，处于 prepare 状态的事务存在于 binlog 中，那么该事务会在存储引擎内部进行提交，这样该事务就同时存在于存储引擎和 binlog 中。**

为了保证数据的安全性，以上列出的 3 个步骤都需要调用 fsync 将数据持久化到磁盘。由于在引擎内部 prepare 完成的事务可以通过binlog 恢复，所以通常情况下第三个 fsync 是可以省略的。

另外，MySQL 内部两阶段提交需要开启 ```innodb_support_xa=true```，默认开启。这个参数就是支持分布式事务两段式事务提交。redo 和 binlog 数据一致性就是靠这个两段式提交来完成的，如果关闭会造成事务数据的丢失。

## 为什么需要保证二进制日志的写入顺序和InnoDB层事务提交顺序一致性呢？
上面提到单个事务的二阶段提交过程，能够保证存储引擎和 binlog 日志保持一致，但是在并发的情况下怎么保证InnoDB层事务日志和MySQL数据库二进制日志的提交的顺序一致？当多个事务并发提交的情况，如果 binlog 和存储引擎顺序不一致会造成什么影响？

这是因为备份及恢复需要，例如通过 xtrabackup 或 ibbackup 这种物理备份工具进行备份时，并使用备份来建立复制，如下图：
![binlog乱序示意图](/img/mysql/binlog乱序示意图.png)   
如上图，事务按照 T1、T2、T3 顺序开始执行，将二进制日志（按照T1、T2、T3顺序）写入日志文件系统缓冲，调用 fsync() 进行一次group commit 将日志文件永久写入磁盘，但是存储引擎提交的顺序为 T2、T3、T1。当 T2、T3 提交事务之后，若通过在线物理备份进行数据库恢复来建立复制时，因为在 innoDB 存储引擎层会检测事务 T3 在上下两层都完成了事务提交，不需要在进行恢复了，此时主备数据不一致（搭建Slave时，change master to的日志偏移量记录 T3 在事务位置之后）。

为了解决以上问题，在早期的 MySQL 5.6 版本之前，通过 prepare_commit_mutex 锁以串行的方式来保证 MySQL 数据库上层二进制日志和 innodb 存储引擎层的事务提交顺序一致，然后会导致组提交（group commit）特性无法生效。为了满足数据的持久化需求，一个完整事务的提交最多会导致 3 次 fsync 操作。为了提高 MySQL 在开启 binlog 的情况下单位时间内的事务提交数，就必须减少每个事务提交过程中导致的fsync的调用次数。所以，MySQL 从 5.6 版本开始加入了 binlog group commit 技术（MariaDB 5.3版本开始引入）。

MySQL 数据库内部在 prepare redo 阶段获取 prepare_commit_mutex 锁，一次只能有一个事务可获取该 mutex。通过这个臭名昭著 prepare_commit_mutex 锁，将 redo log 和 binlog 刷盘串行化，串行化的目的也仅仅是为了保证 redo log 和 Binlog一致，继而无法实现 group commit，牺牲了性能。整个过程如下图：
![binlog顺序示意图](/img/mysql/binlog顺序示意图.png)   
上图可以看出在prepare_commit_mutex，只有当上一个事务commit后释放锁，下一个事务才可以进行prepare操作，并且在每个事务过程中Binary log没有fsync()的调用。由于内存数据写入磁盘的开销很大，如果频繁fsync()把日志数据永久写入磁盘数据库的性能将会急剧下降。此时MySQL数据库提供sync_binlog参数来设置多少个binlog日志产生的时候调用一次fsync()把二进制日志刷入磁盘来提高整体性能。

上图所示 MySQL 开启 binlog 时使用 prepare_commit_mutex 和 sync_log 保证二进制日志和存储引擎顺序保持一致，prepare_commit_mutex 的锁机制造成高并发提交事务的时候性能非常差而且二进制日志也无法 group commit。

这个问题早在 2010 年的 MySQL 数据库大会中提出，Facebook MySQL 技术组，Percona 公司都提出过解决方案，最后由 MariaDB 数据库的开发人员 Kristian Nielsen 完成了最终的”完美”解决方案。在这种情况下，不但 MySQL 数据库上层二进制日志写入是 group commit 的，InnoDB 存储引擎层也是 group commit 的。此外还移除了原先的锁 prepare_commit_mutex，从而大大提高了数据库的整体性。MySQL 5.6 采用了类似的实现方式，并将其称为 BLGC（Binary Log Group Commit），并把事务提交过程分成三个阶段，Flush stage、Sync stage、Commit stage。
## BLGC（Binary Log Group Commit）组提交
MySQL 5.6 BLGC 技术出现后，在这种情况下，不但 MySQL 数据库上层二进制日志写入是 group commit 的，InnoDB 存储引擎层也是 group commit 的。此外还移除了原先的锁 prepare_commit_mutex，从而大大提高了数据库的整体性。其事务的提交（commit）过程分成三个阶段，Flush stage、Sync stage、Commit stage。如下图：

![组提交示意图](/img/mysql/组提交示意图.png)   

Binlog 组提交的基本思想是，引入队列机制保证 Innodb commit 顺序与 binlog 落盘顺序一致，并将事务分组，组内的 binlog 刷盘动作交给一个事务进行，实现组提交目的。在 MySQL 数据库上层进行提交时首先按顺序将其放入一个队列中，队列中的第一个事务称为 leader，其他事务称为 follow，leader 控制着 follow 的行为。

从上图可以看出，每个阶段都有一个队列，每个队列有一个 mutex 保护，约定进入队列第一个线程为 leader，其他线程为 follower，所有事情交由 leader去做，leader 做完所有动作后，通知 follower 刷盘结束。BLGC 就是将事务提交分为了 3 个阶段，FLUSH 阶段，SYNC 阶段和 COMMIT 阶段。
* Flush Stage: 将每个事务的二进制日志写入内存中。
    1. 持有Lock_log mutex [leader持有，follower等待]。
    2. 获取队列中的一组 binlog(队列中的所有事务)。
    3. 将binlog buffer 到 I/O cache。
    4. 通知dump线程dump binlog。
* Sync Stage: 将内存中的二进制日志刷新到磁盘，若队列中有多个事务，那么仅一次 fsync 操作就完成了二进制日志的写入，这就是 BLGC。
    1. 释放 Lock_log mutex，持有Lock_sync mutex[leader持有，follower等待]。
    2. 将一组binlog 落盘(sync动作，最耗时，假设sync_binlog为1)。
* Commit Stage: leader 根据顺序调用存储引擎层事务的提交，Innodb本身就支持 group commit，因此修复了原先由于锁 prepare_commit_mutex 导致 group commit 失效的问题。
    1. 释放 Lock_sync mutex，持有 Lock_commit mutex[leader持有，follower等待]。
    2. 遍历队列中的事务，逐一进行 innodb commit。
    3. 释放 Lock_commit mutex。
    4. 唤醒队列中等待的线程。

说明：由于有多个队列，每个队列各自有 mutex 保护，队列之间是顺序的，约定进入队列的一个线程为 leader，因此 FLUSH 阶段的 leader 可能是 SYNC 阶段的 follower，但是 follower 永远是 follower。

当有一组事务在进行 commit 阶段时，其他新事物可以进行 Flush 阶段，从而使 group commit 不断生效。当然 group commit 的效果由队列中事务的数量决定，若每次队列中仅有一个事务，那么可能效果和之前差不多，甚至会更差。但当提交的事务越多时，group commit 的效果越明显，数据库性能的提升也就越大。

MySQL 提供了一个参数 binlog_max_flush_queue_time（MySQL 5.7.9版本失效），默认值为 0，用来控制 MySQL 5.6 新增的 BLGC（binary log group commit），就是二进制日志组提交中 Flush 阶段中等待的时间，即使之前的一组事务完成提交，当前一组的事务也不马上进入 Sync 阶段，而是至少需要等待一段时间，这样做的好处是 group commit 的事务数量更多，然而这也可能会导致事务的响应时间变慢。该参数默认为 0 表示不等待，且推荐设置依然为0。除非用户的 MySQL 数据库系统中有大量的连接（如100个连接），并且不断地在进行事务的写入或更新操作。

MySQL 5.7 Parallel replication 实现主备多线程复制基于主库 BLGC（Binary Log Group Commit）机制，并在 Binary log 日志中标识同一组事务的last_commited=N和该组事务内所有的事务提交顺序。为了增加一组事务内的事务数量提高备库组提交时的并发量引入了binlog_group_commit_sync_delay=N和binlog_group_commit_sync_no_delay_count=N

注：binlog_max_flush_queue_time在MySQL的5.7.9及之后版本不再生效）参数，MySQL等待binlog_group_commit_sync_delay毫秒直到达到binlog_group_commit_sync_no_delay_count事务个数时，将进行一次组提交。

## 参考文献
[知乎](https://zhuanlan.zhihu.com/p/58011817)
[知乎](https://jkzhao.github.io/2018/04/16/MySQL%E6%97%A5%E5%BF%97%E5%8A%9F%E8%83%BD%E8%AF%A6%E8%A7%A3/)

[MySQL 中Redo与Binlog顺序一致性问题](http://go.fire80.com/Detail/article/id/78.html)